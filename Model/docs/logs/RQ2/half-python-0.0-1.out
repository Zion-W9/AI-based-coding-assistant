@ Stage 2
2022-08-18 04:22:56 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.0, batch_size=32, batch_size_valid=32, best_checkpoint_metric='bleu', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, dstore_filename=None, dstore_size=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 6}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, k=5, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, knn_lambda=0.5, knn_sim_metric=None, knn_temperature=10, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=15, max_source_positions=1024, max_target_positions=1024, max_tokens=None, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, move_dstore_to_mem=False, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, only_train_final_output=False, optimizer='adam', optimizer_overrides='{}', partially_finetune=False, patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, probe=32, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/cluster/jgu/scratch/ssr/cli/model/plbart_base.pt', save_dir='/home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX', save_interval=1, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, sentencepiece_model='/home/cluster/jgu/scratch/ssr/cli/sentencepiece/sentencepiece.bpe.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='python', stop_time_hours=0, target_lang='en_XX', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_gpu_to_search=False, use_knn_datastore=False, use_old_adam=False, user_dir='/home/cluster/jgu/scratch/ssr/cli', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=1000, weight_decay=0.0, zero_sharding='none')
2022-08-18 04:22:56 | INFO | fairseq.tasks.translation | [python] dictionary: 50001 types
2022-08-18 04:22:56 | INFO | fairseq.tasks.translation | [en_XX] dictionary: 50001 types
2022-08-18 04:22:56 | INFO | fairseq.data.data_utils | loaded 18505 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/valid.python-en_XX.python
2022-08-18 04:22:56 | INFO | fairseq.data.data_utils | loaded 18505 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/valid.python-en_XX.en_XX
2022-08-18 04:22:56 | INFO | fairseq.tasks.translation | /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin valid python-en_XX 18505 examples
2022-08-18 04:22:59 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50005, 768, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=50005, bias=False)
  )
  (classification_heads): ModuleDict()
)
2022-08-18 04:22:59 | INFO | fairseq_cli.train | task: translation_from_pretrained_bart (TranslationFromPretrainedBARTTask)
2022-08-18 04:22:59 | INFO | fairseq_cli.train | model: mbart_base (BARTModel)
2022-08-18 04:22:59 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2022-08-18 04:22:59 | INFO | fairseq_cli.train | num. model params: 139220736 (num. trained: 139220736)
2022-08-18 04:23:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-08-18 04:23:03 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-08-18 04:23:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-08-18 04:23:03 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.749 GB ; name = Tesla V100-SXM2-32GB                    
2022-08-18 04:23:03 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2022-08-18 04:23:03 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2022-08-18 04:23:03 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 32
2022-08-18 04:23:05 | INFO | fairseq.trainer | loaded checkpoint /home/cluster/jgu/scratch/ssr/cli/model/plbart_base.pt (epoch 11 @ 0 updates)
2022-08-18 04:23:05 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2022-08-18 04:23:05 | INFO | fairseq.trainer | loading train data for epoch 1
2022-08-18 04:23:06 | INFO | fairseq.data.data_utils | loaded 55538 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/train.python-en_XX.python
2022-08-18 04:23:06 | INFO | fairseq.data.data_utils | loaded 55538 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/train.python-en_XX.en_XX
2022-08-18 04:23:06 | INFO | fairseq.tasks.translation | /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin train python-en_XX 55538 examples
2022-08-18 04:23:06 | INFO | fairseq.trainer | begin training epoch 1
2022-08-18 04:23:18 | INFO | train_inner | {"epoch": 1, "update": 0.058, "loss": "8.876", "nll_loss": "7.16", "ppl": "143.01", "wps": "3353.4", "ups": "8.16", "wpb": "411.6", "bsz": "31.9", "num_updates": "100", "lr": "5e-06", "gnorm": "34.654", "train_wall": "12", "wall": "15"}
2022-08-18 04:23:31 | INFO | train_inner | {"epoch": 1, "update": 0.115, "loss": "6.349", "nll_loss": "4.637", "ppl": "24.88", "wps": "3287.9", "ups": "8.09", "wpb": "406.5", "bsz": "32", "num_updates": "200", "lr": "1e-05", "gnorm": "6.74", "train_wall": "12", "wall": "27"}
2022-08-18 04:23:42 | INFO | train_inner | {"epoch": 1, "update": 0.173, "loss": "6.009", "nll_loss": "4.355", "ppl": "20.47", "wps": "3542.6", "ups": "8.51", "wpb": "416.3", "bsz": "32", "num_updates": "300", "lr": "1.5e-05", "gnorm": "5.553", "train_wall": "12", "wall": "39"}
2022-08-18 04:23:54 | INFO | train_inner | {"epoch": 1, "update": 0.23, "loss": "5.812", "nll_loss": "4.175", "ppl": "18.07", "wps": "3376.2", "ups": "8.48", "wpb": "398.1", "bsz": "32", "num_updates": "400", "lr": "2e-05", "gnorm": "5.662", "train_wall": "12", "wall": "51"}
2022-08-18 04:24:05 | INFO | train_inner | {"epoch": 1, "update": 0.288, "loss": "5.67", "nll_loss": "4.036", "ppl": "16.4", "wps": "3612.4", "ups": "8.93", "wpb": "404.7", "bsz": "32", "num_updates": "500", "lr": "2.5e-05", "gnorm": "5.09", "train_wall": "11", "wall": "62"}
2022-08-18 04:24:18 | INFO | train_inner | {"epoch": 1, "update": 0.346, "loss": "5.634", "nll_loss": "4.012", "ppl": "16.13", "wps": "3255.5", "ups": "8.08", "wpb": "402.7", "bsz": "32", "num_updates": "600", "lr": "3e-05", "gnorm": "4.907", "train_wall": "12", "wall": "75"}
2022-08-18 04:24:31 | INFO | train_inner | {"epoch": 1, "update": 0.403, "loss": "5.633", "nll_loss": "4.019", "ppl": "16.21", "wps": "3304.6", "ups": "7.83", "wpb": "422.3", "bsz": "32", "num_updates": "700", "lr": "3.5e-05", "gnorm": "4.533", "train_wall": "13", "wall": "87"}
2022-08-18 04:24:43 | INFO | train_inner | {"epoch": 1, "update": 0.461, "loss": "5.555", "nll_loss": "3.939", "ppl": "15.34", "wps": "3318.3", "ups": "7.93", "wpb": "418.6", "bsz": "32", "num_updates": "800", "lr": "4e-05", "gnorm": "4.514", "train_wall": "12", "wall": "100"}
2022-08-18 04:24:55 | INFO | train_inner | {"epoch": 1, "update": 0.518, "loss": "5.47", "nll_loss": "3.853", "ppl": "14.45", "wps": "3211.7", "ups": "8.2", "wpb": "391.5", "bsz": "32", "num_updates": "900", "lr": "4.5e-05", "gnorm": "4.504", "train_wall": "12", "wall": "112"}
2022-08-18 04:25:06 | INFO | train_inner | {"epoch": 1, "update": 0.576, "loss": "5.414", "nll_loss": "3.798", "ppl": "13.9", "wps": "3562.9", "ups": "9.09", "wpb": "391.9", "bsz": "32", "num_updates": "1000", "lr": "5e-05", "gnorm": "4.332", "train_wall": "11", "wall": "123"}
2022-08-18 04:25:19 | INFO | train_inner | {"epoch": 1, "update": 0.634, "loss": "5.443", "nll_loss": "3.831", "ppl": "14.23", "wps": "3378.2", "ups": "8.08", "wpb": "418.2", "bsz": "32", "num_updates": "1100", "lr": "4.9995e-05", "gnorm": "4.264", "train_wall": "12", "wall": "136"}
2022-08-18 04:25:32 | INFO | train_inner | {"epoch": 1, "update": 0.691, "loss": "5.484", "nll_loss": "3.884", "ppl": "14.77", "wps": "3292.8", "ups": "7.76", "wpb": "424.1", "bsz": "32", "num_updates": "1200", "lr": "4.999e-05", "gnorm": "4.022", "train_wall": "13", "wall": "148"}
2022-08-18 04:25:43 | INFO | train_inner | {"epoch": 1, "update": 0.749, "loss": "5.395", "nll_loss": "3.784", "ppl": "13.77", "wps": "3537.1", "ups": "8.53", "wpb": "414.9", "bsz": "32", "num_updates": "1300", "lr": "4.9985e-05", "gnorm": "4.13", "train_wall": "12", "wall": "160"}
2022-08-18 04:25:55 | INFO | train_inner | {"epoch": 1, "update": 0.806, "loss": "5.344", "nll_loss": "3.734", "ppl": "13.31", "wps": "3539.9", "ups": "8.4", "wpb": "421.4", "bsz": "32", "num_updates": "1400", "lr": "4.998e-05", "gnorm": "3.888", "train_wall": "12", "wall": "172"}
2022-08-18 04:26:09 | INFO | train_inner | {"epoch": 1, "update": 0.864, "loss": "5.481", "nll_loss": "3.89", "ppl": "14.83", "wps": "3187.6", "ups": "7.51", "wpb": "424.6", "bsz": "32", "num_updates": "1500", "lr": "4.9975e-05", "gnorm": "4.045", "train_wall": "13", "wall": "185"}
2022-08-18 04:26:20 | INFO | train_inner | {"epoch": 1, "update": 0.922, "loss": "5.232", "nll_loss": "3.617", "ppl": "12.27", "wps": "3299.4", "ups": "8.56", "wpb": "385.5", "bsz": "32", "num_updates": "1600", "lr": "4.997e-05", "gnorm": "4.019", "train_wall": "12", "wall": "197"}
2022-08-18 04:26:33 | INFO | train_inner | {"epoch": 1, "update": 0.979, "loss": "5.315", "nll_loss": "3.71", "ppl": "13.08", "wps": "3358.9", "ups": "8.05", "wpb": "417.4", "bsz": "32", "num_updates": "1700", "lr": "4.9965e-05", "gnorm": "3.904", "train_wall": "12", "wall": "209"}
2022-08-18 04:26:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
/net/cephfs/scratch/jgu/ssr/fairseq/utils.py:342: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-08-18 04:29:38 | INFO | valid | {"epoch": 1, "valid_loss": "5.195", "valid_nll_loss": "3.524", "valid_ppl": "11.51", "valid_bleu": "9.24", "valid_wps": "1315.8", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "1736"}
2022-08-18 04:29:38 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 04:29:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 1 @ 1736 updates, score 9.24) (writing took 4.9154611602425575 seconds)
2022-08-18 04:29:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2022-08-18 04:29:43 | INFO | train | {"epoch": 1, "train_loss": "5.764", "train_nll_loss": "4.136", "train_ppl": "17.59", "train_wps": "1793.6", "train_ups": "4.37", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "1736", "train_lr": "4.99632e-05", "train_gnorm": "6.347", "train_train_wall": "208", "train_wall": "400"}
2022-08-18 04:29:43 | INFO | fairseq.trainer | begin training epoch 2
/net/cephfs/scratch/jgu/ssr/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/net/cephfs/scratch/jgu/ssr/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = idx // beam_size
2022-08-18 04:29:51 | INFO | train_inner | {"epoch": 2, "update": 1.037, "loss": "5.07", "nll_loss": "3.431", "ppl": "10.79", "wps": "196.6", "ups": "0.5", "wpb": "390", "bsz": "32", "num_updates": "1800", "lr": "4.996e-05", "gnorm": "3.962", "train_wall": "11", "wall": "408"}
2022-08-18 04:30:03 | INFO | train_inner | {"epoch": 2, "update": 1.094, "loss": "4.894", "nll_loss": "3.226", "ppl": "9.36", "wps": "3300.8", "ups": "8.5", "wpb": "388.2", "bsz": "32", "num_updates": "1900", "lr": "4.9955e-05", "gnorm": "3.967", "train_wall": "12", "wall": "420"}
2022-08-18 04:30:14 | INFO | train_inner | {"epoch": 2, "update": 1.152, "loss": "4.923", "nll_loss": "3.258", "ppl": "9.56", "wps": "3812.1", "ups": "9.28", "wpb": "410.7", "bsz": "32", "num_updates": "2000", "lr": "4.99499e-05", "gnorm": "3.888", "train_wall": "11", "wall": "430"}
2022-08-18 04:30:27 | INFO | train_inner | {"epoch": 2, "update": 1.21, "loss": "5.089", "nll_loss": "3.446", "ppl": "10.9", "wps": "3407.5", "ups": "7.65", "wpb": "445.4", "bsz": "32", "num_updates": "2100", "lr": "4.99449e-05", "gnorm": "3.92", "train_wall": "13", "wall": "443"}
2022-08-18 04:30:39 | INFO | train_inner | {"epoch": 2, "update": 1.267, "loss": "4.904", "nll_loss": "3.246", "ppl": "9.49", "wps": "3172.1", "ups": "7.94", "wpb": "399.3", "bsz": "31.9", "num_updates": "2200", "lr": "4.99399e-05", "gnorm": "3.946", "train_wall": "12", "wall": "456"}
2022-08-18 04:30:51 | INFO | train_inner | {"epoch": 2, "update": 1.325, "loss": "4.894", "nll_loss": "3.234", "ppl": "9.41", "wps": "3255.5", "ups": "8.21", "wpb": "396.6", "bsz": "32", "num_updates": "2300", "lr": "4.99349e-05", "gnorm": "3.935", "train_wall": "12", "wall": "468"}
2022-08-18 04:31:04 | INFO | train_inner | {"epoch": 2, "update": 1.382, "loss": "4.865", "nll_loss": "3.205", "ppl": "9.22", "wps": "3144", "ups": "8.03", "wpb": "391.5", "bsz": "32", "num_updates": "2400", "lr": "4.99299e-05", "gnorm": "3.976", "train_wall": "12", "wall": "481"}
2022-08-18 04:31:16 | INFO | train_inner | {"epoch": 2, "update": 1.44, "loss": "4.957", "nll_loss": "3.31", "ppl": "9.92", "wps": "3280.6", "ups": "8.05", "wpb": "407.6", "bsz": "32", "num_updates": "2500", "lr": "4.99249e-05", "gnorm": "3.911", "train_wall": "12", "wall": "493"}
2022-08-18 04:31:29 | INFO | train_inner | {"epoch": 2, "update": 1.498, "loss": "4.972", "nll_loss": "3.328", "ppl": "10.04", "wps": "3368.1", "ups": "8.16", "wpb": "412.9", "bsz": "32", "num_updates": "2600", "lr": "4.99199e-05", "gnorm": "3.912", "train_wall": "12", "wall": "505"}
2022-08-18 04:31:41 | INFO | train_inner | {"epoch": 2, "update": 1.555, "loss": "4.935", "nll_loss": "3.285", "ppl": "9.75", "wps": "3485.5", "ups": "8.17", "wpb": "426.9", "bsz": "32", "num_updates": "2700", "lr": "4.99149e-05", "gnorm": "3.867", "train_wall": "12", "wall": "518"}
2022-08-18 04:31:53 | INFO | train_inner | {"epoch": 2, "update": 1.613, "loss": "4.938", "nll_loss": "3.291", "ppl": "9.79", "wps": "3415.9", "ups": "8.15", "wpb": "419.2", "bsz": "32", "num_updates": "2800", "lr": "4.99099e-05", "gnorm": "3.874", "train_wall": "12", "wall": "530"}
2022-08-18 04:32:05 | INFO | train_inner | {"epoch": 2, "update": 1.671, "loss": "5.019", "nll_loss": "3.383", "ppl": "10.43", "wps": "3708", "ups": "8.39", "wpb": "441.8", "bsz": "32", "num_updates": "2900", "lr": "4.99049e-05", "gnorm": "3.847", "train_wall": "12", "wall": "542"}
2022-08-18 04:32:17 | INFO | train_inner | {"epoch": 2, "update": 1.728, "loss": "4.85", "nll_loss": "3.197", "ppl": "9.17", "wps": "3236.8", "ups": "8.14", "wpb": "397.8", "bsz": "32", "num_updates": "3000", "lr": "4.98999e-05", "gnorm": "3.982", "train_wall": "12", "wall": "554"}
2022-08-18 04:32:29 | INFO | train_inner | {"epoch": 2, "update": 1.786, "loss": "4.937", "nll_loss": "3.296", "ppl": "9.82", "wps": "3486.9", "ups": "8.22", "wpb": "424.3", "bsz": "32", "num_updates": "3100", "lr": "4.98949e-05", "gnorm": "3.857", "train_wall": "12", "wall": "566"}
2022-08-18 04:32:41 | INFO | train_inner | {"epoch": 2, "update": 1.843, "loss": "4.894", "nll_loss": "3.25", "ppl": "9.51", "wps": "3504.9", "ups": "8.5", "wpb": "412.5", "bsz": "32", "num_updates": "3200", "lr": "4.98899e-05", "gnorm": "3.906", "train_wall": "12", "wall": "578"}
2022-08-18 04:32:53 | INFO | train_inner | {"epoch": 2, "update": 1.901, "loss": "4.87", "nll_loss": "3.221", "ppl": "9.33", "wps": "3529.3", "ups": "8.64", "wpb": "408.6", "bsz": "32", "num_updates": "3300", "lr": "4.98849e-05", "gnorm": "3.874", "train_wall": "11", "wall": "590"}
2022-08-18 04:33:05 | INFO | train_inner | {"epoch": 2, "update": 1.959, "loss": "4.787", "nll_loss": "3.13", "ppl": "8.75", "wps": "3309.5", "ups": "8.27", "wpb": "400.2", "bsz": "32", "num_updates": "3400", "lr": "4.98799e-05", "gnorm": "3.91", "train_wall": "12", "wall": "602"}
2022-08-18 04:33:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 04:35:48 | INFO | valid | {"epoch": 2, "valid_loss": "5.03", "valid_nll_loss": "3.314", "valid_ppl": "9.95", "valid_bleu": "11.99", "valid_wps": "1557.6", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "3472", "valid_best_bleu": "11.99"}
2022-08-18 04:35:48 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 04:35:53 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 2 @ 3472 updates, score 11.99) (writing took 5.129287920892239 seconds)
2022-08-18 04:35:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2022-08-18 04:35:53 | INFO | train | {"epoch": 2, "train_loss": "4.917", "train_nll_loss": "3.265", "train_ppl": "9.61", "train_wps": "1925.9", "train_ups": "4.7", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "3472", "train_lr": "4.98763e-05", "train_gnorm": "3.909", "train_train_wall": "208", "train_wall": "769"}
2022-08-18 04:35:53 | INFO | fairseq.trainer | begin training epoch 3
2022-08-18 04:35:57 | INFO | train_inner | {"epoch": 3, "update": 2.016, "loss": "4.707", "nll_loss": "3.033", "ppl": "8.19", "wps": "240.5", "ups": "0.58", "wpb": "413.5", "bsz": "32", "num_updates": "3500", "lr": "4.98749e-05", "gnorm": "3.827", "train_wall": "13", "wall": "774"}
2022-08-18 04:36:09 | INFO | train_inner | {"epoch": 3, "update": 2.074, "loss": "4.35", "nll_loss": "2.611", "ppl": "6.11", "wps": "3453.8", "ups": "8.43", "wpb": "409.9", "bsz": "32", "num_updates": "3600", "lr": "4.98699e-05", "gnorm": "3.913", "train_wall": "12", "wall": "785"}
2022-08-18 04:36:21 | INFO | train_inner | {"epoch": 3, "update": 2.131, "loss": "4.337", "nll_loss": "2.601", "ppl": "6.07", "wps": "3422.3", "ups": "8.38", "wpb": "408.6", "bsz": "32", "num_updates": "3700", "lr": "4.98649e-05", "gnorm": "3.918", "train_wall": "12", "wall": "797"}
2022-08-18 04:36:33 | INFO | train_inner | {"epoch": 3, "update": 2.189, "loss": "4.382", "nll_loss": "2.653", "ppl": "6.29", "wps": "3218.2", "ups": "7.81", "wpb": "412.1", "bsz": "32", "num_updates": "3800", "lr": "4.98599e-05", "gnorm": "3.976", "train_wall": "13", "wall": "810"}
2022-08-18 04:36:46 | INFO | train_inner | {"epoch": 3, "update": 2.247, "loss": "4.453", "nll_loss": "2.738", "ppl": "6.67", "wps": "3410.9", "ups": "8.25", "wpb": "413.4", "bsz": "32", "num_updates": "3900", "lr": "4.98549e-05", "gnorm": "4.007", "train_wall": "12", "wall": "822"}
2022-08-18 04:36:58 | INFO | train_inner | {"epoch": 3, "update": 2.304, "loss": "4.414", "nll_loss": "2.692", "ppl": "6.46", "wps": "3260.9", "ups": "8.22", "wpb": "396.8", "bsz": "32", "num_updates": "4000", "lr": "4.98498e-05", "gnorm": "4.105", "train_wall": "12", "wall": "835"}
2022-08-18 04:37:10 | INFO | train_inner | {"epoch": 3, "update": 2.362, "loss": "4.383", "nll_loss": "2.66", "ppl": "6.32", "wps": "3235.8", "ups": "8.06", "wpb": "401.3", "bsz": "32", "num_updates": "4100", "lr": "4.98448e-05", "gnorm": "4.015", "train_wall": "12", "wall": "847"}
2022-08-18 04:37:22 | INFO | train_inner | {"epoch": 3, "update": 2.419, "loss": "4.282", "nll_loss": "2.547", "ppl": "5.84", "wps": "3272.8", "ups": "8.58", "wpb": "381.3", "bsz": "32", "num_updates": "4200", "lr": "4.98398e-05", "gnorm": "4.109", "train_wall": "12", "wall": "859"}
2022-08-18 04:37:34 | INFO | train_inner | {"epoch": 3, "update": 2.477, "loss": "4.487", "nll_loss": "2.778", "ppl": "6.86", "wps": "3453.5", "ups": "8.2", "wpb": "421", "bsz": "32", "num_updates": "4300", "lr": "4.98348e-05", "gnorm": "4.067", "train_wall": "12", "wall": "871"}
2022-08-18 04:37:46 | INFO | train_inner | {"epoch": 3, "update": 2.535, "loss": "4.512", "nll_loss": "2.81", "ppl": "7.01", "wps": "3548.9", "ups": "8.62", "wpb": "411.8", "bsz": "32", "num_updates": "4400", "lr": "4.98298e-05", "gnorm": "4.158", "train_wall": "11", "wall": "882"}
2022-08-18 04:37:57 | INFO | train_inner | {"epoch": 3, "update": 2.592, "loss": "4.364", "nll_loss": "2.644", "ppl": "6.25", "wps": "3606.1", "ups": "9.06", "wpb": "397.9", "bsz": "32", "num_updates": "4500", "lr": "4.98248e-05", "gnorm": "4.056", "train_wall": "11", "wall": "893"}
2022-08-18 04:38:09 | INFO | train_inner | {"epoch": 3, "update": 2.65, "loss": "4.436", "nll_loss": "2.726", "ppl": "6.62", "wps": "3313.4", "ups": "8.12", "wpb": "407.9", "bsz": "31.9", "num_updates": "4600", "lr": "4.98198e-05", "gnorm": "4.145", "train_wall": "12", "wall": "906"}
2022-08-18 04:38:21 | INFO | train_inner | {"epoch": 3, "update": 2.707, "loss": "4.396", "nll_loss": "2.684", "ppl": "6.43", "wps": "3362", "ups": "8.49", "wpb": "396.1", "bsz": "32", "num_updates": "4700", "lr": "4.98148e-05", "gnorm": "4.141", "train_wall": "12", "wall": "917"}
2022-08-18 04:38:33 | INFO | train_inner | {"epoch": 3, "update": 2.765, "loss": "4.453", "nll_loss": "2.746", "ppl": "6.71", "wps": "3513.9", "ups": "8.4", "wpb": "418.4", "bsz": "32", "num_updates": "4800", "lr": "4.98098e-05", "gnorm": "4.108", "train_wall": "12", "wall": "929"}
2022-08-18 04:38:45 | INFO | train_inner | {"epoch": 3, "update": 2.823, "loss": "4.518", "nll_loss": "2.822", "ppl": "7.07", "wps": "3437.5", "ups": "8.09", "wpb": "424.7", "bsz": "32", "num_updates": "4900", "lr": "4.98048e-05", "gnorm": "4.064", "train_wall": "12", "wall": "942"}
2022-08-18 04:38:59 | INFO | train_inner | {"epoch": 3, "update": 2.88, "loss": "4.452", "nll_loss": "2.748", "ppl": "6.72", "wps": "3095.5", "ups": "7.38", "wpb": "419.2", "bsz": "32", "num_updates": "5000", "lr": "4.97998e-05", "gnorm": "4.108", "train_wall": "13", "wall": "955"}
2022-08-18 04:39:11 | INFO | train_inner | {"epoch": 3, "update": 2.938, "loss": "4.585", "nll_loss": "2.897", "ppl": "7.45", "wps": "3472.3", "ups": "7.83", "wpb": "443.6", "bsz": "32", "num_updates": "5100", "lr": "4.97948e-05", "gnorm": "4.157", "train_wall": "13", "wall": "968"}
2022-08-18 04:39:23 | INFO | train_inner | {"epoch": 3, "update": 2.995, "loss": "4.476", "nll_loss": "2.776", "ppl": "6.85", "wps": "3478", "ups": "8.4", "wpb": "413.8", "bsz": "32", "num_updates": "5200", "lr": "4.97898e-05", "gnorm": "4.121", "train_wall": "12", "wall": "980"}
2022-08-18 04:39:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 04:41:55 | INFO | valid | {"epoch": 3, "valid_loss": "4.961", "valid_nll_loss": "3.249", "valid_ppl": "9.5", "valid_bleu": "13.68", "valid_wps": "1578.4", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "5208", "valid_best_bleu": "13.68"}
2022-08-18 04:41:55 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 04:42:01 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 3 @ 5208 updates, score 13.68) (writing took 5.155684269964695 seconds)
2022-08-18 04:42:01 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2022-08-18 04:42:01 | INFO | train | {"epoch": 3, "train_loss": "4.429", "train_nll_loss": "2.715", "train_ppl": "6.57", "train_wps": "1935.1", "train_ups": "4.72", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "5208", "train_lr": "4.97894e-05", "train_gnorm": "4.066", "train_train_wall": "208", "train_wall": "1137"}
2022-08-18 04:42:01 | INFO | fairseq.trainer | begin training epoch 4
2022-08-18 04:42:13 | INFO | train_inner | {"epoch": 4, "update": 3.053, "loss": "3.994", "nll_loss": "2.209", "ppl": "4.62", "wps": "241.1", "ups": "0.59", "wpb": "409.1", "bsz": "32", "num_updates": "5300", "lr": "4.97848e-05", "gnorm": "3.998", "train_wall": "12", "wall": "1150"}
2022-08-18 04:42:25 | INFO | train_inner | {"epoch": 4, "update": 3.111, "loss": "3.888", "nll_loss": "2.087", "ppl": "4.25", "wps": "3168.3", "ups": "8.08", "wpb": "392.2", "bsz": "32", "num_updates": "5400", "lr": "4.97798e-05", "gnorm": "4.143", "train_wall": "12", "wall": "1162"}
2022-08-18 04:42:37 | INFO | train_inner | {"epoch": 4, "update": 3.168, "loss": "4.044", "nll_loss": "2.265", "ppl": "4.81", "wps": "3811.2", "ups": "8.76", "wpb": "434.9", "bsz": "32", "num_updates": "5500", "lr": "4.97748e-05", "gnorm": "4.112", "train_wall": "11", "wall": "1173"}
2022-08-18 04:42:49 | INFO | train_inner | {"epoch": 4, "update": 3.226, "loss": "4.032", "nll_loss": "2.254", "ppl": "4.77", "wps": "3324.5", "ups": "8.02", "wpb": "414.3", "bsz": "32", "num_updates": "5600", "lr": "4.97698e-05", "gnorm": "4.279", "train_wall": "12", "wall": "1186"}
2022-08-18 04:43:02 | INFO | train_inner | {"epoch": 4, "update": 3.283, "loss": "4.061", "nll_loss": "2.284", "ppl": "4.87", "wps": "3344.2", "ups": "7.92", "wpb": "422.3", "bsz": "32", "num_updates": "5700", "lr": "4.97648e-05", "gnorm": "4.261", "train_wall": "12", "wall": "1199"}
2022-08-18 04:43:14 | INFO | train_inner | {"epoch": 4, "update": 3.341, "loss": "3.961", "nll_loss": "2.175", "ppl": "4.51", "wps": "3302.7", "ups": "8.33", "wpb": "396.5", "bsz": "32", "num_updates": "5800", "lr": "4.97598e-05", "gnorm": "4.289", "train_wall": "12", "wall": "1211"}
2022-08-18 04:43:25 | INFO | train_inner | {"epoch": 4, "update": 3.399, "loss": "3.962", "nll_loss": "2.177", "ppl": "4.52", "wps": "3632", "ups": "8.94", "wpb": "406.4", "bsz": "32", "num_updates": "5900", "lr": "4.97548e-05", "gnorm": "4.305", "train_wall": "11", "wall": "1222"}
2022-08-18 04:43:36 | INFO | train_inner | {"epoch": 4, "update": 3.456, "loss": "3.952", "nll_loss": "2.169", "ppl": "4.5", "wps": "3469.2", "ups": "8.74", "wpb": "396.9", "bsz": "32", "num_updates": "6000", "lr": "4.97497e-05", "gnorm": "4.29", "train_wall": "11", "wall": "1233"}
2022-08-18 04:43:49 | INFO | train_inner | {"epoch": 4, "update": 3.514, "loss": "3.972", "nll_loss": "2.195", "ppl": "4.58", "wps": "3185.2", "ups": "8.22", "wpb": "387.6", "bsz": "32", "num_updates": "6100", "lr": "4.97447e-05", "gnorm": "4.39", "train_wall": "12", "wall": "1245"}
2022-08-18 04:44:00 | INFO | train_inner | {"epoch": 4, "update": 3.571, "loss": "4.146", "nll_loss": "2.389", "ppl": "5.24", "wps": "3642", "ups": "8.55", "wpb": "425.8", "bsz": "32", "num_updates": "6200", "lr": "4.97397e-05", "gnorm": "4.31", "train_wall": "12", "wall": "1257"}
2022-08-18 04:44:13 | INFO | train_inner | {"epoch": 4, "update": 3.629, "loss": "4.113", "nll_loss": "2.352", "ppl": "5.11", "wps": "3291.8", "ups": "7.83", "wpb": "420.2", "bsz": "32", "num_updates": "6300", "lr": "4.97347e-05", "gnorm": "4.342", "train_wall": "13", "wall": "1270"}
2022-08-18 04:44:27 | INFO | train_inner | {"epoch": 4, "update": 3.687, "loss": "4.144", "nll_loss": "2.387", "ppl": "5.23", "wps": "3213.8", "ups": "7.39", "wpb": "435", "bsz": "32", "num_updates": "6400", "lr": "4.97297e-05", "gnorm": "4.35", "train_wall": "13", "wall": "1283"}
2022-08-18 04:44:39 | INFO | train_inner | {"epoch": 4, "update": 3.744, "loss": "4.014", "nll_loss": "2.242", "ppl": "4.73", "wps": "3308.1", "ups": "8.07", "wpb": "409.7", "bsz": "32", "num_updates": "6500", "lr": "4.97247e-05", "gnorm": "4.311", "train_wall": "12", "wall": "1296"}
2022-08-18 04:44:50 | INFO | train_inner | {"epoch": 4, "update": 3.802, "loss": "3.959", "nll_loss": "2.184", "ppl": "4.54", "wps": "3382.8", "ups": "8.69", "wpb": "389.2", "bsz": "31.9", "num_updates": "6600", "lr": "4.97197e-05", "gnorm": "4.441", "train_wall": "11", "wall": "1307"}
2022-08-18 04:45:02 | INFO | train_inner | {"epoch": 4, "update": 3.859, "loss": "4.079", "nll_loss": "2.321", "ppl": "5", "wps": "3416.6", "ups": "8.31", "wpb": "411.3", "bsz": "32", "num_updates": "6700", "lr": "4.97147e-05", "gnorm": "4.42", "train_wall": "12", "wall": "1319"}
2022-08-18 04:45:15 | INFO | train_inner | {"epoch": 4, "update": 3.917, "loss": "4.076", "nll_loss": "2.317", "ppl": "4.98", "wps": "3342.1", "ups": "8.08", "wpb": "413.7", "bsz": "32", "num_updates": "6800", "lr": "4.97097e-05", "gnorm": "4.399", "train_wall": "12", "wall": "1332"}
2022-08-18 04:45:27 | INFO | train_inner | {"epoch": 4, "update": 3.975, "loss": "4.088", "nll_loss": "2.334", "ppl": "5.04", "wps": "3391.5", "ups": "8.2", "wpb": "413.5", "bsz": "32", "num_updates": "6900", "lr": "4.97047e-05", "gnorm": "4.375", "train_wall": "12", "wall": "1344"}
2022-08-18 04:45:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 04:48:12 | INFO | valid | {"epoch": 4, "valid_loss": "5.013", "valid_nll_loss": "3.285", "valid_ppl": "9.75", "valid_bleu": "15.75", "valid_wps": "1493.7", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "6944", "valid_best_bleu": "15.75"}
2022-08-18 04:48:12 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 04:48:17 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 4 @ 6944 updates, score 15.75) (writing took 5.124558702111244 seconds)
2022-08-18 04:48:17 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2022-08-18 04:48:17 | INFO | train | {"epoch": 4, "train_loss": "4.028", "train_nll_loss": "2.255", "train_ppl": "4.77", "train_wps": "1892.3", "train_ups": "4.61", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "6944", "train_lr": "4.97025e-05", "train_gnorm": "4.297", "train_train_wall": "208", "train_wall": "1514"}
2022-08-18 04:48:17 | INFO | fairseq.trainer | begin training epoch 5
2022-08-18 04:48:24 | INFO | train_inner | {"epoch": 5, "update": 4.032, "loss": "3.73", "nll_loss": "1.912", "ppl": "3.76", "wps": "222.4", "ups": "0.57", "wpb": "393.7", "bsz": "32", "num_updates": "7000", "lr": "4.96997e-05", "gnorm": "4.252", "train_wall": "12", "wall": "1521"}
2022-08-18 04:48:36 | INFO | train_inner | {"epoch": 5, "update": 4.09, "loss": "3.645", "nll_loss": "1.804", "ppl": "3.49", "wps": "3513.4", "ups": "8.18", "wpb": "429.4", "bsz": "32", "num_updates": "7100", "lr": "4.96947e-05", "gnorm": "4.231", "train_wall": "12", "wall": "1533"}
2022-08-18 04:48:48 | INFO | train_inner | {"epoch": 5, "update": 4.147, "loss": "3.62", "nll_loss": "1.777", "ppl": "3.43", "wps": "3435.8", "ups": "8.37", "wpb": "410.7", "bsz": "32", "num_updates": "7200", "lr": "4.96897e-05", "gnorm": "4.251", "train_wall": "12", "wall": "1545"}
2022-08-18 04:49:00 | INFO | train_inner | {"epoch": 5, "update": 4.205, "loss": "3.684", "nll_loss": "1.853", "ppl": "3.61", "wps": "3335.3", "ups": "8.14", "wpb": "409.9", "bsz": "32", "num_updates": "7300", "lr": "4.96847e-05", "gnorm": "4.383", "train_wall": "12", "wall": "1557"}
2022-08-18 04:49:11 | INFO | train_inner | {"epoch": 5, "update": 4.263, "loss": "3.543", "nll_loss": "1.696", "ppl": "3.24", "wps": "3512.1", "ups": "9.21", "wpb": "381.4", "bsz": "32", "num_updates": "7400", "lr": "4.96797e-05", "gnorm": "4.41", "train_wall": "11", "wall": "1568"}
2022-08-18 04:49:24 | INFO | train_inner | {"epoch": 5, "update": 4.32, "loss": "3.572", "nll_loss": "1.731", "ppl": "3.32", "wps": "3067.1", "ups": "8", "wpb": "383.4", "bsz": "32", "num_updates": "7500", "lr": "4.96747e-05", "gnorm": "4.447", "train_wall": "12", "wall": "1581"}
2022-08-18 04:49:36 | INFO | train_inner | {"epoch": 5, "update": 4.378, "loss": "3.674", "nll_loss": "1.846", "ppl": "3.6", "wps": "3440.8", "ups": "8.36", "wpb": "411.5", "bsz": "32", "num_updates": "7600", "lr": "4.96697e-05", "gnorm": "4.438", "train_wall": "12", "wall": "1593"}
2022-08-18 04:49:47 | INFO | train_inner | {"epoch": 5, "update": 4.435, "loss": "3.695", "nll_loss": "1.871", "ppl": "3.66", "wps": "3642.6", "ups": "8.76", "wpb": "415.6", "bsz": "32", "num_updates": "7700", "lr": "4.96647e-05", "gnorm": "4.43", "train_wall": "11", "wall": "1604"}
2022-08-18 04:49:59 | INFO | train_inner | {"epoch": 5, "update": 4.493, "loss": "3.748", "nll_loss": "1.93", "ppl": "3.81", "wps": "3424.4", "ups": "8.14", "wpb": "420.7", "bsz": "32", "num_updates": "7800", "lr": "4.96597e-05", "gnorm": "4.562", "train_wall": "12", "wall": "1616"}
2022-08-18 04:50:12 | INFO | train_inner | {"epoch": 5, "update": 4.551, "loss": "3.735", "nll_loss": "1.918", "ppl": "3.78", "wps": "3259.7", "ups": "8.05", "wpb": "404.9", "bsz": "32", "num_updates": "7900", "lr": "4.96547e-05", "gnorm": "4.515", "train_wall": "12", "wall": "1629"}
2022-08-18 04:50:26 | INFO | train_inner | {"epoch": 5, "update": 4.608, "loss": "3.742", "nll_loss": "1.925", "ppl": "3.8", "wps": "3045.6", "ups": "7.17", "wpb": "424.8", "bsz": "32", "num_updates": "8000", "lr": "4.96496e-05", "gnorm": "4.565", "train_wall": "14", "wall": "1643"}
2022-08-18 04:50:38 | INFO | train_inner | {"epoch": 5, "update": 4.666, "loss": "3.771", "nll_loss": "1.96", "ppl": "3.89", "wps": "3598.1", "ups": "8.53", "wpb": "421.7", "bsz": "32", "num_updates": "8100", "lr": "4.96446e-05", "gnorm": "4.541", "train_wall": "12", "wall": "1654"}
2022-08-18 04:50:50 | INFO | train_inner | {"epoch": 5, "update": 4.724, "loss": "3.832", "nll_loss": "2.03", "ppl": "4.08", "wps": "3438.5", "ups": "8.01", "wpb": "429.3", "bsz": "32", "num_updates": "8200", "lr": "4.96396e-05", "gnorm": "4.543", "train_wall": "12", "wall": "1667"}
2022-08-18 04:51:02 | INFO | train_inner | {"epoch": 5, "update": 4.781, "loss": "3.713", "nll_loss": "1.897", "ppl": "3.72", "wps": "3337.6", "ups": "8.1", "wpb": "412.1", "bsz": "32", "num_updates": "8300", "lr": "4.96346e-05", "gnorm": "4.619", "train_wall": "12", "wall": "1679"}
2022-08-18 04:51:14 | INFO | train_inner | {"epoch": 5, "update": 4.839, "loss": "3.692", "nll_loss": "1.874", "ppl": "3.67", "wps": "3615.5", "ups": "8.97", "wpb": "402.9", "bsz": "31.9", "num_updates": "8400", "lr": "4.96296e-05", "gnorm": "4.584", "train_wall": "11", "wall": "1690"}
2022-08-18 04:51:25 | INFO | train_inner | {"epoch": 5, "update": 4.896, "loss": "3.663", "nll_loss": "1.842", "ppl": "3.59", "wps": "3418.4", "ups": "8.47", "wpb": "403.8", "bsz": "32", "num_updates": "8500", "lr": "4.96246e-05", "gnorm": "4.593", "train_wall": "12", "wall": "1702"}
2022-08-18 04:51:38 | INFO | train_inner | {"epoch": 5, "update": 4.954, "loss": "3.79", "nll_loss": "1.986", "ppl": "3.96", "wps": "3311", "ups": "7.87", "wpb": "420.4", "bsz": "32", "num_updates": "8600", "lr": "4.96196e-05", "gnorm": "4.607", "train_wall": "13", "wall": "1715"}
2022-08-18 04:51:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 04:54:34 | INFO | valid | {"epoch": 5, "valid_loss": "5.04", "valid_nll_loss": "3.319", "valid_ppl": "9.98", "valid_bleu": "17.5", "valid_wps": "1437.4", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "8680", "valid_best_bleu": "17.5"}
2022-08-18 04:54:34 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 04:54:39 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 5 @ 8680 updates, score 17.5) (writing took 5.207765519618988 seconds)
2022-08-18 04:54:39 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2022-08-18 04:54:39 | INFO | train | {"epoch": 5, "train_loss": "3.692", "train_nll_loss": "1.868", "train_ppl": "3.65", "train_wps": "1863.1", "train_ups": "4.54", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "8680", "train_lr": "4.96156e-05", "train_gnorm": "4.478", "train_train_wall": "208", "train_wall": "1896"}
2022-08-18 04:54:39 | INFO | fairseq.trainer | begin training epoch 6
2022-08-18 04:54:43 | INFO | train_inner | {"epoch": 6, "update": 5.012, "loss": "3.609", "nll_loss": "1.778", "ppl": "3.43", "wps": "218.4", "ups": "0.54", "wpb": "403.2", "bsz": "32", "num_updates": "8700", "lr": "4.96146e-05", "gnorm": "4.511", "train_wall": "13", "wall": "1899"}
2022-08-18 04:54:54 | INFO | train_inner | {"epoch": 6, "update": 5.069, "loss": "3.229", "nll_loss": "1.334", "ppl": "2.52", "wps": "3523.2", "ups": "9.03", "wpb": "390.1", "bsz": "32", "num_updates": "8800", "lr": "4.96096e-05", "gnorm": "4.18", "train_wall": "11", "wall": "1910"}
2022-08-18 04:55:06 | INFO | train_inner | {"epoch": 6, "update": 5.127, "loss": "3.394", "nll_loss": "1.52", "ppl": "2.87", "wps": "3429.9", "ups": "8.19", "wpb": "418.9", "bsz": "32", "num_updates": "8900", "lr": "4.96046e-05", "gnorm": "4.342", "train_wall": "12", "wall": "1923"}
2022-08-18 04:55:18 | INFO | train_inner | {"epoch": 6, "update": 5.184, "loss": "3.419", "nll_loss": "1.55", "ppl": "2.93", "wps": "3466.9", "ups": "8.15", "wpb": "425.4", "bsz": "32", "num_updates": "9000", "lr": "4.95996e-05", "gnorm": "4.411", "train_wall": "12", "wall": "1935"}
2022-08-18 04:55:31 | INFO | train_inner | {"epoch": 6, "update": 5.242, "loss": "3.261", "nll_loss": "1.37", "ppl": "2.59", "wps": "3220.6", "ups": "8.08", "wpb": "398.6", "bsz": "32", "num_updates": "9100", "lr": "4.95946e-05", "gnorm": "4.375", "train_wall": "12", "wall": "1947"}
2022-08-18 04:55:43 | INFO | train_inner | {"epoch": 6, "update": 5.3, "loss": "3.337", "nll_loss": "1.457", "ppl": "2.75", "wps": "3294.2", "ups": "8.2", "wpb": "401.6", "bsz": "32", "num_updates": "9200", "lr": "4.95896e-05", "gnorm": "4.48", "train_wall": "12", "wall": "1960"}
2022-08-18 04:55:55 | INFO | train_inner | {"epoch": 6, "update": 5.357, "loss": "3.438", "nll_loss": "1.572", "ppl": "2.97", "wps": "3441.9", "ups": "7.9", "wpb": "435.7", "bsz": "32", "num_updates": "9300", "lr": "4.95846e-05", "gnorm": "4.519", "train_wall": "13", "wall": "1972"}
2022-08-18 04:56:07 | INFO | train_inner | {"epoch": 6, "update": 5.415, "loss": "3.436", "nll_loss": "1.572", "ppl": "2.97", "wps": "3562.5", "ups": "8.62", "wpb": "413.2", "bsz": "32", "num_updates": "9400", "lr": "4.95796e-05", "gnorm": "4.548", "train_wall": "11", "wall": "1984"}
2022-08-18 04:56:19 | INFO | train_inner | {"epoch": 6, "update": 5.472, "loss": "3.435", "nll_loss": "1.571", "ppl": "2.97", "wps": "3402.3", "ups": "8.23", "wpb": "413.2", "bsz": "32", "num_updates": "9500", "lr": "4.95746e-05", "gnorm": "4.59", "train_wall": "12", "wall": "1996"}
2022-08-18 04:56:32 | INFO | train_inner | {"epoch": 6, "update": 5.53, "loss": "3.448", "nll_loss": "1.587", "ppl": "3", "wps": "3277.6", "ups": "7.75", "wpb": "423", "bsz": "32", "num_updates": "9600", "lr": "4.95696e-05", "gnorm": "4.709", "train_wall": "13", "wall": "2009"}
2022-08-18 04:56:44 | INFO | train_inner | {"epoch": 6, "update": 5.588, "loss": "3.487", "nll_loss": "1.633", "ppl": "3.1", "wps": "3526.1", "ups": "8.3", "wpb": "424.7", "bsz": "32", "num_updates": "9700", "lr": "4.95646e-05", "gnorm": "4.585", "train_wall": "12", "wall": "2021"}
2022-08-18 04:56:56 | INFO | train_inner | {"epoch": 6, "update": 5.645, "loss": "3.39", "nll_loss": "1.526", "ppl": "2.88", "wps": "3412.8", "ups": "8.44", "wpb": "404.3", "bsz": "32", "num_updates": "9800", "lr": "4.95596e-05", "gnorm": "4.623", "train_wall": "12", "wall": "2033"}
2022-08-18 04:57:09 | INFO | train_inner | {"epoch": 6, "update": 5.703, "loss": "3.419", "nll_loss": "1.557", "ppl": "2.94", "wps": "3225.5", "ups": "7.93", "wpb": "406.9", "bsz": "32", "num_updates": "9900", "lr": "4.95546e-05", "gnorm": "4.66", "train_wall": "12", "wall": "2045"}
2022-08-18 04:57:20 | INFO | train_inner | {"epoch": 6, "update": 5.76, "loss": "3.447", "nll_loss": "1.591", "ppl": "3.01", "wps": "3560.8", "ups": "8.92", "wpb": "399", "bsz": "32", "num_updates": "10000", "lr": "4.95495e-05", "gnorm": "4.651", "train_wall": "11", "wall": "2057"}
2022-08-18 04:57:31 | INFO | train_inner | {"epoch": 6, "update": 5.818, "loss": "3.462", "nll_loss": "1.608", "ppl": "3.05", "wps": "3469.1", "ups": "8.66", "wpb": "400.7", "bsz": "32", "num_updates": "10100", "lr": "4.95445e-05", "gnorm": "4.777", "train_wall": "11", "wall": "2068"}
2022-08-18 04:57:44 | INFO | train_inner | {"epoch": 6, "update": 5.876, "loss": "3.496", "nll_loss": "1.648", "ppl": "3.13", "wps": "3383.3", "ups": "8.13", "wpb": "416", "bsz": "32", "num_updates": "10200", "lr": "4.95395e-05", "gnorm": "4.763", "train_wall": "12", "wall": "2080"}
2022-08-18 04:57:56 | INFO | train_inner | {"epoch": 6, "update": 5.933, "loss": "3.38", "nll_loss": "1.516", "ppl": "2.86", "wps": "3270.2", "ups": "8.27", "wpb": "395.6", "bsz": "31.9", "num_updates": "10300", "lr": "4.95345e-05", "gnorm": "4.65", "train_wall": "12", "wall": "2093"}
2022-08-18 04:58:09 | INFO | train_inner | {"epoch": 6, "update": 5.991, "loss": "3.436", "nll_loss": "1.58", "ppl": "2.99", "wps": "3183", "ups": "7.79", "wpb": "408.7", "bsz": "32", "num_updates": "10400", "lr": "4.95295e-05", "gnorm": "4.728", "train_wall": "13", "wall": "2105"}
2022-08-18 04:58:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:01:01 | INFO | valid | {"epoch": 6, "valid_loss": "5.178", "valid_nll_loss": "3.464", "valid_ppl": "11.04", "valid_bleu": "19.71", "valid_wps": "1403.2", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "10416", "valid_best_bleu": "19.71"}
2022-08-18 05:01:01 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:01:06 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 6 @ 10416 updates, score 19.71) (writing took 5.088632874190807 seconds)
2022-08-18 05:01:06 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2022-08-18 05:01:06 | INFO | train | {"epoch": 6, "train_loss": "3.406", "train_nll_loss": "1.54", "train_ppl": "2.91", "train_wps": "1842.6", "train_ups": "4.49", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "10416", "train_lr": "4.95287e-05", "train_gnorm": "4.561", "train_train_wall": "208", "train_wall": "2282"}
2022-08-18 05:01:06 | INFO | fairseq.trainer | begin training epoch 7
2022-08-18 05:01:17 | INFO | train_inner | {"epoch": 7, "update": 6.048, "loss": "3.173", "nll_loss": "1.268", "ppl": "2.41", "wps": "231.3", "ups": "0.53", "wpb": "435", "bsz": "32", "num_updates": "10500", "lr": "4.95245e-05", "gnorm": "4.282", "train_wall": "12", "wall": "2293"}
2022-08-18 05:01:29 | INFO | train_inner | {"epoch": 7, "update": 6.106, "loss": "3.122", "nll_loss": "1.212", "ppl": "2.32", "wps": "3319.5", "ups": "8.11", "wpb": "409.5", "bsz": "32", "num_updates": "10600", "lr": "4.95195e-05", "gnorm": "4.192", "train_wall": "12", "wall": "2306"}
2022-08-18 05:01:42 | INFO | train_inner | {"epoch": 7, "update": 6.164, "loss": "3.11", "nll_loss": "1.201", "ppl": "2.3", "wps": "3116.2", "ups": "7.67", "wpb": "406.4", "bsz": "32", "num_updates": "10700", "lr": "4.95145e-05", "gnorm": "4.263", "train_wall": "13", "wall": "2319"}
2022-08-18 05:01:54 | INFO | train_inner | {"epoch": 7, "update": 6.221, "loss": "3.157", "nll_loss": "1.255", "ppl": "2.39", "wps": "3387.8", "ups": "8.24", "wpb": "411", "bsz": "31.9", "num_updates": "10800", "lr": "4.95095e-05", "gnorm": "4.318", "train_wall": "12", "wall": "2331"}
2022-08-18 05:02:07 | INFO | train_inner | {"epoch": 7, "update": 6.279, "loss": "3.125", "nll_loss": "1.213", "ppl": "2.32", "wps": "3341.2", "ups": "8.01", "wpb": "417.3", "bsz": "32", "num_updates": "10900", "lr": "4.95045e-05", "gnorm": "4.454", "train_wall": "12", "wall": "2343"}
2022-08-18 05:02:17 | INFO | train_inner | {"epoch": 7, "update": 6.336, "loss": "3.08", "nll_loss": "1.169", "ppl": "2.25", "wps": "3645.7", "ups": "9.22", "wpb": "395.3", "bsz": "32", "num_updates": "11000", "lr": "4.94995e-05", "gnorm": "4.385", "train_wall": "11", "wall": "2354"}
2022-08-18 05:02:30 | INFO | train_inner | {"epoch": 7, "update": 6.394, "loss": "3.256", "nll_loss": "1.366", "ppl": "2.58", "wps": "3458", "ups": "7.82", "wpb": "442", "bsz": "32", "num_updates": "11100", "lr": "4.94945e-05", "gnorm": "4.443", "train_wall": "13", "wall": "2367"}
2022-08-18 05:02:42 | INFO | train_inner | {"epoch": 7, "update": 6.452, "loss": "3.154", "nll_loss": "1.252", "ppl": "2.38", "wps": "3436.7", "ups": "8.38", "wpb": "410.1", "bsz": "32", "num_updates": "11200", "lr": "4.94895e-05", "gnorm": "4.522", "train_wall": "12", "wall": "2379"}
2022-08-18 05:02:55 | INFO | train_inner | {"epoch": 7, "update": 6.509, "loss": "3.196", "nll_loss": "1.299", "ppl": "2.46", "wps": "3311.6", "ups": "7.79", "wpb": "425.1", "bsz": "32", "num_updates": "11300", "lr": "4.94845e-05", "gnorm": "4.562", "train_wall": "13", "wall": "2392"}
2022-08-18 05:03:07 | INFO | train_inner | {"epoch": 7, "update": 6.567, "loss": "3.136", "nll_loss": "1.234", "ppl": "2.35", "wps": "3264.3", "ups": "8.14", "wpb": "400.8", "bsz": "32", "num_updates": "11400", "lr": "4.94795e-05", "gnorm": "4.559", "train_wall": "12", "wall": "2404"}
2022-08-18 05:03:20 | INFO | train_inner | {"epoch": 7, "update": 6.624, "loss": "3.172", "nll_loss": "1.275", "ppl": "2.42", "wps": "3251.6", "ups": "8.04", "wpb": "404.3", "bsz": "32", "num_updates": "11500", "lr": "4.94745e-05", "gnorm": "4.754", "train_wall": "12", "wall": "2417"}
2022-08-18 05:03:31 | INFO | train_inner | {"epoch": 7, "update": 6.682, "loss": "3.155", "nll_loss": "1.261", "ppl": "2.4", "wps": "3532", "ups": "9.03", "wpb": "391.3", "bsz": "32", "num_updates": "11600", "lr": "4.94695e-05", "gnorm": "4.573", "train_wall": "11", "wall": "2428"}
2022-08-18 05:03:43 | INFO | train_inner | {"epoch": 7, "update": 6.74, "loss": "3.263", "nll_loss": "1.381", "ppl": "2.6", "wps": "3423.3", "ups": "8.21", "wpb": "417.1", "bsz": "32", "num_updates": "11700", "lr": "4.94645e-05", "gnorm": "4.639", "train_wall": "12", "wall": "2440"}
2022-08-18 05:03:56 | INFO | train_inner | {"epoch": 7, "update": 6.797, "loss": "3.191", "nll_loss": "1.298", "ppl": "2.46", "wps": "3180.5", "ups": "7.81", "wpb": "407.2", "bsz": "32", "num_updates": "11800", "lr": "4.94595e-05", "gnorm": "4.735", "train_wall": "13", "wall": "2453"}
2022-08-18 05:04:08 | INFO | train_inner | {"epoch": 7, "update": 6.855, "loss": "3.239", "nll_loss": "1.354", "ppl": "2.56", "wps": "3320.4", "ups": "8.04", "wpb": "413.2", "bsz": "32", "num_updates": "11900", "lr": "4.94545e-05", "gnorm": "4.711", "train_wall": "12", "wall": "2465"}
2022-08-18 05:04:19 | INFO | train_inner | {"epoch": 7, "update": 6.912, "loss": "3.117", "nll_loss": "1.219", "ppl": "2.33", "wps": "3523", "ups": "9.26", "wpb": "380.6", "bsz": "32", "num_updates": "12000", "lr": "4.94494e-05", "gnorm": "4.69", "train_wall": "11", "wall": "2476"}
2022-08-18 05:04:30 | INFO | train_inner | {"epoch": 7, "update": 6.97, "loss": "3.152", "nll_loss": "1.26", "ppl": "2.4", "wps": "3506.8", "ups": "8.97", "wpb": "391.1", "bsz": "32", "num_updates": "12100", "lr": "4.94444e-05", "gnorm": "4.701", "train_wall": "11", "wall": "2487"}
2022-08-18 05:04:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:07:38 | INFO | valid | {"epoch": 7, "valid_loss": "5.21", "valid_nll_loss": "3.517", "valid_ppl": "11.44", "valid_bleu": "21.47", "valid_wps": "1317.8", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "12152", "valid_best_bleu": "21.47"}
2022-08-18 05:07:38 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:07:43 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 7 @ 12152 updates, score 21.47) (writing took 5.021661177277565 seconds)
2022-08-18 05:07:43 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2022-08-18 05:07:43 | INFO | train | {"epoch": 7, "train_loss": "3.17", "train_nll_loss": "1.271", "train_ppl": "2.41", "train_wps": "1792.1", "train_ups": "4.37", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "12152", "train_lr": "4.94418e-05", "train_gnorm": "4.52", "train_train_wall": "208", "train_wall": "2680"}
2022-08-18 05:07:43 | INFO | fairseq.trainer | begin training epoch 8
2022-08-18 05:07:50 | INFO | train_inner | {"epoch": 8, "update": 7.028, "loss": "3.114", "nll_loss": "1.211", "ppl": "2.31", "wps": "213.4", "ups": "0.5", "wpb": "425.9", "bsz": "32", "num_updates": "12200", "lr": "4.94394e-05", "gnorm": "4.314", "train_wall": "13", "wall": "2687"}
2022-08-18 05:08:01 | INFO | train_inner | {"epoch": 8, "update": 7.085, "loss": "2.953", "nll_loss": "1.025", "ppl": "2.03", "wps": "3677.6", "ups": "8.69", "wpb": "423.1", "bsz": "32", "num_updates": "12300", "lr": "4.94344e-05", "gnorm": "4.045", "train_wall": "11", "wall": "2698"}
2022-08-18 05:08:13 | INFO | train_inner | {"epoch": 8, "update": 7.143, "loss": "2.909", "nll_loss": "0.976", "ppl": "1.97", "wps": "3488.5", "ups": "8.37", "wpb": "416.8", "bsz": "32", "num_updates": "12400", "lr": "4.94294e-05", "gnorm": "3.965", "train_wall": "12", "wall": "2710"}
2022-08-18 05:08:25 | INFO | train_inner | {"epoch": 8, "update": 7.2, "loss": "2.878", "nll_loss": "0.938", "ppl": "1.92", "wps": "3461.8", "ups": "8.56", "wpb": "404.4", "bsz": "32", "num_updates": "12500", "lr": "4.94244e-05", "gnorm": "4.174", "train_wall": "12", "wall": "2722"}
2022-08-18 05:08:38 | INFO | train_inner | {"epoch": 8, "update": 7.258, "loss": "2.911", "nll_loss": "0.978", "ppl": "1.97", "wps": "3177.6", "ups": "7.76", "wpb": "409.5", "bsz": "32", "num_updates": "12600", "lr": "4.94194e-05", "gnorm": "4.255", "train_wall": "13", "wall": "2735"}
2022-08-18 05:08:50 | INFO | train_inner | {"epoch": 8, "update": 7.316, "loss": "2.849", "nll_loss": "0.912", "ppl": "1.88", "wps": "3144.6", "ups": "8.37", "wpb": "375.8", "bsz": "32", "num_updates": "12700", "lr": "4.94144e-05", "gnorm": "4.258", "train_wall": "12", "wall": "2747"}
2022-08-18 05:09:02 | INFO | train_inner | {"epoch": 8, "update": 7.373, "loss": "2.948", "nll_loss": "1.022", "ppl": "2.03", "wps": "3258.9", "ups": "8.05", "wpb": "404.9", "bsz": "32", "num_updates": "12800", "lr": "4.94094e-05", "gnorm": "4.333", "train_wall": "12", "wall": "2759"}
2022-08-18 05:09:15 | INFO | train_inner | {"epoch": 8, "update": 7.431, "loss": "2.973", "nll_loss": "1.051", "ppl": "2.07", "wps": "3336.7", "ups": "8.1", "wpb": "411.8", "bsz": "32", "num_updates": "12900", "lr": "4.94044e-05", "gnorm": "4.31", "train_wall": "12", "wall": "2771"}
2022-08-18 05:09:27 | INFO | train_inner | {"epoch": 8, "update": 7.488, "loss": "2.967", "nll_loss": "1.047", "ppl": "2.07", "wps": "3224.6", "ups": "8.05", "wpb": "400.6", "bsz": "32", "num_updates": "13000", "lr": "4.93994e-05", "gnorm": "4.404", "train_wall": "12", "wall": "2784"}
2022-08-18 05:09:39 | INFO | train_inner | {"epoch": 8, "update": 7.546, "loss": "2.965", "nll_loss": "1.046", "ppl": "2.06", "wps": "3346.7", "ups": "8.58", "wpb": "390", "bsz": "32", "num_updates": "13100", "lr": "4.93944e-05", "gnorm": "4.421", "train_wall": "12", "wall": "2795"}
2022-08-18 05:09:51 | INFO | train_inner | {"epoch": 8, "update": 7.604, "loss": "3.025", "nll_loss": "1.111", "ppl": "2.16", "wps": "3533.3", "ups": "8.36", "wpb": "422.7", "bsz": "32", "num_updates": "13200", "lr": "4.93894e-05", "gnorm": "4.446", "train_wall": "12", "wall": "2807"}
2022-08-18 05:10:02 | INFO | train_inner | {"epoch": 8, "update": 7.661, "loss": "3.019", "nll_loss": "1.106", "ppl": "2.15", "wps": "3414.5", "ups": "8.39", "wpb": "406.9", "bsz": "31.9", "num_updates": "13300", "lr": "4.93844e-05", "gnorm": "4.474", "train_wall": "12", "wall": "2819"}
2022-08-18 05:10:15 | INFO | train_inner | {"epoch": 8, "update": 7.719, "loss": "3.039", "nll_loss": "1.128", "ppl": "2.19", "wps": "3321.5", "ups": "7.92", "wpb": "419.2", "bsz": "32", "num_updates": "13400", "lr": "4.93794e-05", "gnorm": "4.564", "train_wall": "12", "wall": "2832"}
2022-08-18 05:10:27 | INFO | train_inner | {"epoch": 8, "update": 7.776, "loss": "3.09", "nll_loss": "1.188", "ppl": "2.28", "wps": "3500.6", "ups": "8.31", "wpb": "421", "bsz": "32", "num_updates": "13500", "lr": "4.93744e-05", "gnorm": "4.525", "train_wall": "12", "wall": "2844"}
2022-08-18 05:10:39 | INFO | train_inner | {"epoch": 8, "update": 7.834, "loss": "3.061", "nll_loss": "1.153", "ppl": "2.22", "wps": "3589.8", "ups": "8.47", "wpb": "424.1", "bsz": "32", "num_updates": "13600", "lr": "4.93694e-05", "gnorm": "4.58", "train_wall": "12", "wall": "2856"}
2022-08-18 05:10:51 | INFO | train_inner | {"epoch": 8, "update": 7.892, "loss": "3.001", "nll_loss": "1.086", "ppl": "2.12", "wps": "3376.9", "ups": "8.25", "wpb": "409.1", "bsz": "32", "num_updates": "13700", "lr": "4.93644e-05", "gnorm": "4.661", "train_wall": "12", "wall": "2868"}
2022-08-18 05:11:04 | INFO | train_inner | {"epoch": 8, "update": 7.949, "loss": "3.079", "nll_loss": "1.176", "ppl": "2.26", "wps": "3248.7", "ups": "7.75", "wpb": "419.2", "bsz": "32", "num_updates": "13800", "lr": "4.93594e-05", "gnorm": "4.647", "train_wall": "13", "wall": "2881"}
2022-08-18 05:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:14:20 | INFO | valid | {"epoch": 8, "valid_loss": "5.337", "valid_nll_loss": "3.653", "valid_ppl": "12.58", "valid_bleu": "22.81", "valid_wps": "1287.1", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "13888", "valid_best_bleu": "22.81"}
2022-08-18 05:14:20 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:14:25 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 8 @ 13888 updates, score 22.81) (writing took 5.122086025774479 seconds)
2022-08-18 05:14:25 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2022-08-18 05:14:25 | INFO | train | {"epoch": 8, "train_loss": "2.981", "train_nll_loss": "1.061", "train_ppl": "2.09", "train_wps": "1772.6", "train_ups": "4.32", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "13888", "train_lr": "4.9355e-05", "train_gnorm": "4.377", "train_train_wall": "208", "train_wall": "3082"}
2022-08-18 05:14:25 | INFO | fairseq.trainer | begin training epoch 9
2022-08-18 05:14:26 | INFO | train_inner | {"epoch": 9, "update": 8.007, "loss": "2.999", "nll_loss": "1.085", "ppl": "2.12", "wps": "202", "ups": "0.49", "wpb": "408.8", "bsz": "32", "num_updates": "13900", "lr": "4.93544e-05", "gnorm": "4.498", "train_wall": "11", "wall": "3083"}
2022-08-18 05:14:39 | INFO | train_inner | {"epoch": 9, "update": 8.065, "loss": "2.815", "nll_loss": "0.871", "ppl": "1.83", "wps": "3477.6", "ups": "8.05", "wpb": "431.8", "bsz": "32", "num_updates": "14000", "lr": "4.93493e-05", "gnorm": "3.83", "train_wall": "12", "wall": "3096"}
2022-08-18 05:14:51 | INFO | train_inner | {"epoch": 9, "update": 8.122, "loss": "2.808", "nll_loss": "0.863", "ppl": "1.82", "wps": "3470.5", "ups": "8.24", "wpb": "421.1", "bsz": "31.9", "num_updates": "14100", "lr": "4.93443e-05", "gnorm": "4.09", "train_wall": "12", "wall": "3108"}
2022-08-18 05:15:04 | INFO | train_inner | {"epoch": 9, "update": 8.18, "loss": "2.696", "nll_loss": "0.739", "ppl": "1.67", "wps": "3029.6", "ups": "7.89", "wpb": "384.2", "bsz": "32", "num_updates": "14200", "lr": "4.93393e-05", "gnorm": "3.877", "train_wall": "13", "wall": "3120"}
2022-08-18 05:15:16 | INFO | train_inner | {"epoch": 9, "update": 8.237, "loss": "2.826", "nll_loss": "0.886", "ppl": "1.85", "wps": "3520.8", "ups": "8.1", "wpb": "434.8", "bsz": "32", "num_updates": "14300", "lr": "4.93343e-05", "gnorm": "4.037", "train_wall": "12", "wall": "3133"}
2022-08-18 05:15:28 | INFO | train_inner | {"epoch": 9, "update": 8.295, "loss": "2.765", "nll_loss": "0.819", "ppl": "1.76", "wps": "3202.6", "ups": "8.05", "wpb": "397.8", "bsz": "32", "num_updates": "14400", "lr": "4.93293e-05", "gnorm": "4.102", "train_wall": "12", "wall": "3145"}
2022-08-18 05:15:41 | INFO | train_inner | {"epoch": 9, "update": 8.353, "loss": "2.829", "nll_loss": "0.89", "ppl": "1.85", "wps": "3352.3", "ups": "8.02", "wpb": "417.8", "bsz": "32", "num_updates": "14500", "lr": "4.93243e-05", "gnorm": "4.113", "train_wall": "12", "wall": "3158"}
2022-08-18 05:15:53 | INFO | train_inner | {"epoch": 9, "update": 8.41, "loss": "2.796", "nll_loss": "0.856", "ppl": "1.81", "wps": "3325.3", "ups": "8.48", "wpb": "392.2", "bsz": "32", "num_updates": "14600", "lr": "4.93193e-05", "gnorm": "4.127", "train_wall": "12", "wall": "3169"}
2022-08-18 05:16:05 | INFO | train_inner | {"epoch": 9, "update": 8.468, "loss": "2.787", "nll_loss": "0.847", "ppl": "1.8", "wps": "3104.7", "ups": "7.82", "wpb": "397", "bsz": "32", "num_updates": "14700", "lr": "4.93143e-05", "gnorm": "4.102", "train_wall": "13", "wall": "3182"}
2022-08-18 05:16:17 | INFO | train_inner | {"epoch": 9, "update": 8.525, "loss": "2.856", "nll_loss": "0.923", "ppl": "1.9", "wps": "3461.6", "ups": "8.41", "wpb": "411.8", "bsz": "32", "num_updates": "14800", "lr": "4.93093e-05", "gnorm": "4.274", "train_wall": "12", "wall": "3194"}
2022-08-18 05:16:29 | INFO | train_inner | {"epoch": 9, "update": 8.583, "loss": "2.806", "nll_loss": "0.868", "ppl": "1.83", "wps": "3425.4", "ups": "8.48", "wpb": "404.1", "bsz": "32", "num_updates": "14900", "lr": "4.93043e-05", "gnorm": "4.339", "train_wall": "12", "wall": "3206"}
2022-08-18 05:16:41 | INFO | train_inner | {"epoch": 9, "update": 8.641, "loss": "2.83", "nll_loss": "0.894", "ppl": "1.86", "wps": "3383.9", "ups": "8.28", "wpb": "408.8", "bsz": "32", "num_updates": "15000", "lr": "4.92993e-05", "gnorm": "4.308", "train_wall": "12", "wall": "3218"}
2022-08-18 05:16:53 | INFO | train_inner | {"epoch": 9, "update": 8.698, "loss": "2.864", "nll_loss": "0.933", "ppl": "1.91", "wps": "3527.6", "ups": "8.54", "wpb": "413.1", "bsz": "32", "num_updates": "15100", "lr": "4.92943e-05", "gnorm": "4.39", "train_wall": "12", "wall": "3230"}
2022-08-18 05:17:05 | INFO | train_inner | {"epoch": 9, "update": 8.756, "loss": "2.847", "nll_loss": "0.916", "ppl": "1.89", "wps": "3493.8", "ups": "8.56", "wpb": "408.2", "bsz": "32", "num_updates": "15200", "lr": "4.92893e-05", "gnorm": "4.324", "train_wall": "12", "wall": "3241"}
2022-08-18 05:17:16 | INFO | train_inner | {"epoch": 9, "update": 8.813, "loss": "2.835", "nll_loss": "0.903", "ppl": "1.87", "wps": "3426.2", "ups": "8.62", "wpb": "397.7", "bsz": "32", "num_updates": "15300", "lr": "4.92843e-05", "gnorm": "4.428", "train_wall": "11", "wall": "3253"}
2022-08-18 05:17:28 | INFO | train_inner | {"epoch": 9, "update": 8.871, "loss": "2.927", "nll_loss": "1.007", "ppl": "2.01", "wps": "3453.8", "ups": "8.14", "wpb": "424.1", "bsz": "32", "num_updates": "15400", "lr": "4.92793e-05", "gnorm": "4.471", "train_wall": "12", "wall": "3265"}
2022-08-18 05:17:41 | INFO | train_inner | {"epoch": 9, "update": 8.929, "loss": "2.918", "nll_loss": "0.999", "ppl": "2", "wps": "3351.4", "ups": "8.19", "wpb": "409", "bsz": "32", "num_updates": "15500", "lr": "4.92743e-05", "gnorm": "4.471", "train_wall": "12", "wall": "3277"}
2022-08-18 05:17:53 | INFO | train_inner | {"epoch": 9, "update": 8.986, "loss": "2.845", "nll_loss": "0.914", "ppl": "1.88", "wps": "3289.1", "ups": "8.14", "wpb": "403.8", "bsz": "32", "num_updates": "15600", "lr": "4.92693e-05", "gnorm": "4.426", "train_wall": "12", "wall": "3290"}
2022-08-18 05:17:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:21:11 | INFO | valid | {"epoch": 9, "valid_loss": "5.366", "valid_nll_loss": "3.686", "valid_ppl": "12.87", "valid_bleu": "24.14", "valid_wps": "1224.5", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "15624", "valid_best_bleu": "24.14"}
2022-08-18 05:21:11 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:21:16 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 9 @ 15624 updates, score 24.14) (writing took 5.2527052238583565 seconds)
2022-08-18 05:21:16 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2022-08-18 05:21:16 | INFO | train | {"epoch": 9, "train_loss": "2.83", "train_nll_loss": "0.894", "train_ppl": "1.86", "train_wps": "1731.7", "train_ups": "4.22", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "15624", "train_lr": "4.92681e-05", "train_gnorm": "4.22", "train_train_wall": "208", "train_wall": "3493"}
2022-08-18 05:21:16 | INFO | fairseq.trainer | begin training epoch 10
2022-08-18 05:21:25 | INFO | train_inner | {"epoch": 10, "update": 9.044, "loss": "2.706", "nll_loss": "0.754", "ppl": "1.69", "wps": "193.6", "ups": "0.47", "wpb": "411.4", "bsz": "32", "num_updates": "15700", "lr": "4.92643e-05", "gnorm": "3.798", "train_wall": "12", "wall": "3502"}
2022-08-18 05:21:38 | INFO | train_inner | {"epoch": 10, "update": 9.101, "loss": "2.671", "nll_loss": "0.713", "ppl": "1.64", "wps": "3393.4", "ups": "7.86", "wpb": "431.6", "bsz": "32", "num_updates": "15800", "lr": "4.92593e-05", "gnorm": "3.717", "train_wall": "13", "wall": "3515"}
2022-08-18 05:21:50 | INFO | train_inner | {"epoch": 10, "update": 9.159, "loss": "2.684", "nll_loss": "0.728", "ppl": "1.66", "wps": "3408.4", "ups": "8.1", "wpb": "420.8", "bsz": "32", "num_updates": "15900", "lr": "4.92543e-05", "gnorm": "3.763", "train_wall": "12", "wall": "3527"}
2022-08-18 05:22:02 | INFO | train_inner | {"epoch": 10, "update": 9.217, "loss": "2.64", "nll_loss": "0.681", "ppl": "1.6", "wps": "3390.5", "ups": "8.65", "wpb": "391.8", "bsz": "31.9", "num_updates": "16000", "lr": "4.92492e-05", "gnorm": "3.775", "train_wall": "11", "wall": "3539"}
2022-08-18 05:22:14 | INFO | train_inner | {"epoch": 10, "update": 9.274, "loss": "2.677", "nll_loss": "0.726", "ppl": "1.65", "wps": "3264.7", "ups": "8.12", "wpb": "402.2", "bsz": "32", "num_updates": "16100", "lr": "4.92442e-05", "gnorm": "3.8", "train_wall": "12", "wall": "3551"}
2022-08-18 05:22:25 | INFO | train_inner | {"epoch": 10, "update": 9.332, "loss": "2.714", "nll_loss": "0.767", "ppl": "1.7", "wps": "3800.9", "ups": "9.15", "wpb": "415.4", "bsz": "32", "num_updates": "16200", "lr": "4.92392e-05", "gnorm": "3.809", "train_wall": "11", "wall": "3562"}
2022-08-18 05:22:38 | INFO | train_inner | {"epoch": 10, "update": 9.389, "loss": "2.715", "nll_loss": "0.766", "ppl": "1.7", "wps": "3162.9", "ups": "7.58", "wpb": "417", "bsz": "32", "num_updates": "16300", "lr": "4.92342e-05", "gnorm": "3.873", "train_wall": "13", "wall": "3575"}
2022-08-18 05:22:51 | INFO | train_inner | {"epoch": 10, "update": 9.447, "loss": "2.744", "nll_loss": "0.8", "ppl": "1.74", "wps": "3520.2", "ups": "8.3", "wpb": "424.2", "bsz": "32", "num_updates": "16400", "lr": "4.92292e-05", "gnorm": "4.077", "train_wall": "12", "wall": "3587"}
2022-08-18 05:23:02 | INFO | train_inner | {"epoch": 10, "update": 9.505, "loss": "2.69", "nll_loss": "0.739", "ppl": "1.67", "wps": "3556.4", "ups": "8.62", "wpb": "412.7", "bsz": "32", "num_updates": "16500", "lr": "4.92242e-05", "gnorm": "3.976", "train_wall": "11", "wall": "3599"}
2022-08-18 05:23:15 | INFO | train_inner | {"epoch": 10, "update": 9.562, "loss": "2.756", "nll_loss": "0.814", "ppl": "1.76", "wps": "3233.3", "ups": "7.74", "wpb": "417.9", "bsz": "32", "num_updates": "16600", "lr": "4.92192e-05", "gnorm": "4.048", "train_wall": "13", "wall": "3612"}
2022-08-18 05:23:27 | INFO | train_inner | {"epoch": 10, "update": 9.62, "loss": "2.745", "nll_loss": "0.804", "ppl": "1.75", "wps": "3397.6", "ups": "8.32", "wpb": "408.2", "bsz": "32", "num_updates": "16700", "lr": "4.92142e-05", "gnorm": "4.016", "train_wall": "12", "wall": "3624"}
2022-08-18 05:23:40 | INFO | train_inner | {"epoch": 10, "update": 9.677, "loss": "2.753", "nll_loss": "0.812", "ppl": "1.76", "wps": "3397.2", "ups": "7.97", "wpb": "426", "bsz": "32", "num_updates": "16800", "lr": "4.92092e-05", "gnorm": "4.102", "train_wall": "12", "wall": "3636"}
2022-08-18 05:23:52 | INFO | train_inner | {"epoch": 10, "update": 9.735, "loss": "2.741", "nll_loss": "0.799", "ppl": "1.74", "wps": "3228", "ups": "8", "wpb": "403.5", "bsz": "32", "num_updates": "16900", "lr": "4.92042e-05", "gnorm": "4.136", "train_wall": "12", "wall": "3649"}
2022-08-18 05:24:04 | INFO | train_inner | {"epoch": 10, "update": 9.793, "loss": "2.753", "nll_loss": "0.814", "ppl": "1.76", "wps": "3413.4", "ups": "8.38", "wpb": "407.4", "bsz": "32", "num_updates": "17000", "lr": "4.91992e-05", "gnorm": "4.175", "train_wall": "12", "wall": "3661"}
2022-08-18 05:24:16 | INFO | train_inner | {"epoch": 10, "update": 9.85, "loss": "2.679", "nll_loss": "0.732", "ppl": "1.66", "wps": "3295.7", "ups": "8.48", "wpb": "388.5", "bsz": "32", "num_updates": "17100", "lr": "4.91942e-05", "gnorm": "4.1", "train_wall": "12", "wall": "3673"}
2022-08-18 05:24:28 | INFO | train_inner | {"epoch": 10, "update": 9.908, "loss": "2.744", "nll_loss": "0.804", "ppl": "1.75", "wps": "3416.7", "ups": "8.33", "wpb": "410.2", "bsz": "32", "num_updates": "17200", "lr": "4.91892e-05", "gnorm": "4.19", "train_wall": "12", "wall": "3685"}
2022-08-18 05:24:40 | INFO | train_inner | {"epoch": 10, "update": 9.965, "loss": "2.713", "nll_loss": "0.77", "ppl": "1.71", "wps": "3058.5", "ups": "7.92", "wpb": "386.4", "bsz": "32", "num_updates": "17300", "lr": "4.91842e-05", "gnorm": "4.221", "train_wall": "12", "wall": "3697"}
2022-08-18 05:24:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:27:50 | INFO | valid | {"epoch": 10, "valid_loss": "5.455", "valid_nll_loss": "3.81", "valid_ppl": "14.03", "valid_bleu": "24.6", "valid_wps": "1308.2", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "17360", "valid_best_bleu": "24.6"}
2022-08-18 05:27:50 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:27:55 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 10 @ 17360 updates, score 24.6) (writing took 5.0992269068956375 seconds)
2022-08-18 05:27:55 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2022-08-18 05:27:55 | INFO | train | {"epoch": 10, "train_loss": "2.711", "train_nll_loss": "0.764", "train_ppl": "1.7", "train_wps": "1785.2", "train_ups": "4.35", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "17360", "train_lr": "4.91812e-05", "train_gnorm": "3.978", "train_train_wall": "208", "train_wall": "3892"}
2022-08-18 05:27:55 | INFO | fairseq.trainer | begin training epoch 11
2022-08-18 05:28:00 | INFO | train_inner | {"epoch": 11, "update": 10.023, "loss": "2.709", "nll_loss": "0.761", "ppl": "1.69", "wps": "213.3", "ups": "0.5", "wpb": "425.7", "bsz": "32", "num_updates": "17400", "lr": "4.91792e-05", "gnorm": "3.915", "train_wall": "11", "wall": "3897"}
2022-08-18 05:28:12 | INFO | train_inner | {"epoch": 11, "update": 10.081, "loss": "2.582", "nll_loss": "0.618", "ppl": "1.53", "wps": "3339.3", "ups": "8.08", "wpb": "413.1", "bsz": "32", "num_updates": "17500", "lr": "4.91742e-05", "gnorm": "3.434", "train_wall": "12", "wall": "3909"}
2022-08-18 05:28:25 | INFO | train_inner | {"epoch": 11, "update": 10.138, "loss": "2.546", "nll_loss": "0.579", "ppl": "1.49", "wps": "3173.1", "ups": "7.92", "wpb": "400.6", "bsz": "32", "num_updates": "17600", "lr": "4.91692e-05", "gnorm": "3.501", "train_wall": "12", "wall": "3922"}
2022-08-18 05:28:38 | INFO | train_inner | {"epoch": 11, "update": 10.196, "loss": "2.566", "nll_loss": "0.602", "ppl": "1.52", "wps": "3247.4", "ups": "7.96", "wpb": "408", "bsz": "32", "num_updates": "17700", "lr": "4.91642e-05", "gnorm": "3.565", "train_wall": "12", "wall": "3934"}
2022-08-18 05:28:50 | INFO | train_inner | {"epoch": 11, "update": 10.253, "loss": "2.617", "nll_loss": "0.662", "ppl": "1.58", "wps": "3398.3", "ups": "8.18", "wpb": "415.2", "bsz": "32", "num_updates": "17800", "lr": "4.91592e-05", "gnorm": "3.673", "train_wall": "12", "wall": "3947"}
2022-08-18 05:29:02 | INFO | train_inner | {"epoch": 11, "update": 10.311, "loss": "2.563", "nll_loss": "0.601", "ppl": "1.52", "wps": "3112.4", "ups": "8.02", "wpb": "388.2", "bsz": "32", "num_updates": "17900", "lr": "4.91542e-05", "gnorm": "3.536", "train_wall": "12", "wall": "3959"}
2022-08-18 05:29:14 | INFO | train_inner | {"epoch": 11, "update": 10.369, "loss": "2.632", "nll_loss": "0.679", "ppl": "1.6", "wps": "3615", "ups": "8.46", "wpb": "427.4", "bsz": "32", "num_updates": "18000", "lr": "4.91491e-05", "gnorm": "3.668", "train_wall": "12", "wall": "3971"}
2022-08-18 05:29:26 | INFO | train_inner | {"epoch": 11, "update": 10.426, "loss": "2.633", "nll_loss": "0.679", "ppl": "1.6", "wps": "3475.7", "ups": "8.22", "wpb": "422.6", "bsz": "32", "num_updates": "18100", "lr": "4.91441e-05", "gnorm": "3.77", "train_wall": "12", "wall": "3983"}
2022-08-18 05:29:39 | INFO | train_inner | {"epoch": 11, "update": 10.484, "loss": "2.604", "nll_loss": "0.645", "ppl": "1.56", "wps": "3240.3", "ups": "7.86", "wpb": "412.4", "bsz": "32", "num_updates": "18200", "lr": "4.91391e-05", "gnorm": "3.782", "train_wall": "13", "wall": "3996"}
2022-08-18 05:29:51 | INFO | train_inner | {"epoch": 11, "update": 10.541, "loss": "2.618", "nll_loss": "0.666", "ppl": "1.59", "wps": "3141.3", "ups": "8.09", "wpb": "388.4", "bsz": "32", "num_updates": "18300", "lr": "4.91341e-05", "gnorm": "3.762", "train_wall": "12", "wall": "4008"}
2022-08-18 05:30:03 | INFO | train_inner | {"epoch": 11, "update": 10.599, "loss": "2.644", "nll_loss": "0.693", "ppl": "1.62", "wps": "3547.8", "ups": "8.8", "wpb": "403.3", "bsz": "32", "num_updates": "18400", "lr": "4.91291e-05", "gnorm": "3.9", "train_wall": "11", "wall": "4020"}
2022-08-18 05:30:15 | INFO | train_inner | {"epoch": 11, "update": 10.657, "loss": "2.643", "nll_loss": "0.694", "ppl": "1.62", "wps": "3435.6", "ups": "8.15", "wpb": "421.3", "bsz": "32", "num_updates": "18500", "lr": "4.91241e-05", "gnorm": "3.855", "train_wall": "12", "wall": "4032"}
2022-08-18 05:30:27 | INFO | train_inner | {"epoch": 11, "update": 10.714, "loss": "2.594", "nll_loss": "0.639", "ppl": "1.56", "wps": "3220.3", "ups": "8.36", "wpb": "385.2", "bsz": "31.9", "num_updates": "18600", "lr": "4.91191e-05", "gnorm": "3.885", "train_wall": "12", "wall": "4044"}
2022-08-18 05:30:39 | INFO | train_inner | {"epoch": 11, "update": 10.772, "loss": "2.656", "nll_loss": "0.705", "ppl": "1.63", "wps": "3471.7", "ups": "8.22", "wpb": "422.2", "bsz": "32", "num_updates": "18700", "lr": "4.91141e-05", "gnorm": "3.906", "train_wall": "12", "wall": "4056"}
2022-08-18 05:30:51 | INFO | train_inner | {"epoch": 11, "update": 10.829, "loss": "2.643", "nll_loss": "0.695", "ppl": "1.62", "wps": "3318", "ups": "8.24", "wpb": "402.7", "bsz": "32", "num_updates": "18800", "lr": "4.91091e-05", "gnorm": "3.962", "train_wall": "12", "wall": "4068"}
2022-08-18 05:31:04 | INFO | train_inner | {"epoch": 11, "update": 10.887, "loss": "2.696", "nll_loss": "0.753", "ppl": "1.69", "wps": "3394.6", "ups": "8.02", "wpb": "423.1", "bsz": "32", "num_updates": "18900", "lr": "4.91041e-05", "gnorm": "4.066", "train_wall": "12", "wall": "4081"}
2022-08-18 05:31:15 | INFO | train_inner | {"epoch": 11, "update": 10.945, "loss": "2.712", "nll_loss": "0.772", "ppl": "1.71", "wps": "3837.2", "ups": "8.99", "wpb": "426.8", "bsz": "32", "num_updates": "19000", "lr": "4.90991e-05", "gnorm": "4.058", "train_wall": "11", "wall": "4092"}
2022-08-18 05:31:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:34:29 | INFO | valid | {"epoch": 11, "valid_loss": "5.477", "valid_nll_loss": "3.847", "valid_ppl": "14.39", "valid_bleu": "24.93", "valid_wps": "1303.7", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "19096", "valid_best_bleu": "24.93"}
2022-08-18 05:34:29 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:34:34 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 11 @ 19096 updates, score 24.93) (writing took 5.051221385598183 seconds)
2022-08-18 05:34:34 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2022-08-18 05:34:34 | INFO | train | {"epoch": 11, "train_loss": "2.626", "train_nll_loss": "0.672", "train_ppl": "1.59", "train_wps": "1783.4", "train_ups": "4.35", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "19096", "train_lr": "4.90943e-05", "train_gnorm": "3.774", "train_train_wall": "208", "train_wall": "4291"}
2022-08-18 05:34:34 | INFO | fairseq.trainer | begin training epoch 12
2022-08-18 05:34:35 | INFO | train_inner | {"epoch": 12, "update": 11.002, "loss": "2.682", "nll_loss": "0.738", "ppl": "1.67", "wps": "206.1", "ups": "0.5", "wpb": "413.3", "bsz": "32", "num_updates": "19100", "lr": "4.90941e-05", "gnorm": "3.998", "train_wall": "12", "wall": "4292"}
2022-08-18 05:34:47 | INFO | train_inner | {"epoch": 12, "update": 11.06, "loss": "2.48", "nll_loss": "0.508", "ppl": "1.42", "wps": "3325.3", "ups": "8.32", "wpb": "399.6", "bsz": "32", "num_updates": "19200", "lr": "4.90891e-05", "gnorm": "3.134", "train_wall": "12", "wall": "4304"}
2022-08-18 05:34:59 | INFO | train_inner | {"epoch": 12, "update": 11.118, "loss": "2.472", "nll_loss": "0.503", "ppl": "1.42", "wps": "3166.8", "ups": "8.4", "wpb": "376.8", "bsz": "32", "num_updates": "19300", "lr": "4.90841e-05", "gnorm": "3.401", "train_wall": "12", "wall": "4316"}
2022-08-18 05:35:11 | INFO | train_inner | {"epoch": 12, "update": 11.175, "loss": "2.536", "nll_loss": "0.574", "ppl": "1.49", "wps": "3406.3", "ups": "8.36", "wpb": "407.3", "bsz": "32", "num_updates": "19400", "lr": "4.90791e-05", "gnorm": "3.397", "train_wall": "12", "wall": "4328"}
2022-08-18 05:35:23 | INFO | train_inner | {"epoch": 12, "update": 11.233, "loss": "2.525", "nll_loss": "0.561", "ppl": "1.48", "wps": "3419.5", "ups": "8.24", "wpb": "415.1", "bsz": "32", "num_updates": "19500", "lr": "4.90741e-05", "gnorm": "3.526", "train_wall": "12", "wall": "4340"}
2022-08-18 05:35:35 | INFO | train_inner | {"epoch": 12, "update": 11.29, "loss": "2.516", "nll_loss": "0.553", "ppl": "1.47", "wps": "3414.6", "ups": "8.48", "wpb": "402.8", "bsz": "32", "num_updates": "19600", "lr": "4.90691e-05", "gnorm": "3.447", "train_wall": "12", "wall": "4352"}
2022-08-18 05:35:48 | INFO | train_inner | {"epoch": 12, "update": 11.348, "loss": "2.528", "nll_loss": "0.565", "ppl": "1.48", "wps": "3208.2", "ups": "8.05", "wpb": "398.6", "bsz": "32", "num_updates": "19700", "lr": "4.90641e-05", "gnorm": "3.542", "train_wall": "12", "wall": "4364"}
2022-08-18 05:36:01 | INFO | train_inner | {"epoch": 12, "update": 11.406, "loss": "2.555", "nll_loss": "0.597", "ppl": "1.51", "wps": "3184.2", "ups": "7.77", "wpb": "409.7", "bsz": "32", "num_updates": "19800", "lr": "4.90591e-05", "gnorm": "3.55", "train_wall": "13", "wall": "4377"}
2022-08-18 05:36:13 | INFO | train_inner | {"epoch": 12, "update": 11.463, "loss": "2.581", "nll_loss": "0.626", "ppl": "1.54", "wps": "3427", "ups": "8.03", "wpb": "426.5", "bsz": "32", "num_updates": "19900", "lr": "4.90541e-05", "gnorm": "3.578", "train_wall": "12", "wall": "4390"}
2022-08-18 05:36:25 | INFO | train_inner | {"epoch": 12, "update": 11.521, "loss": "2.612", "nll_loss": "0.661", "ppl": "1.58", "wps": "3614.8", "ups": "8.35", "wpb": "433", "bsz": "32", "num_updates": "20000", "lr": "4.9049e-05", "gnorm": "3.676", "train_wall": "12", "wall": "4402"}
2022-08-18 05:36:38 | INFO | train_inner | {"epoch": 12, "update": 11.578, "loss": "2.589", "nll_loss": "0.634", "ppl": "1.55", "wps": "3420.4", "ups": "7.92", "wpb": "431.8", "bsz": "31.9", "num_updates": "20100", "lr": "4.9044e-05", "gnorm": "3.639", "train_wall": "12", "wall": "4414"}
2022-08-18 05:36:49 | INFO | train_inner | {"epoch": 12, "update": 11.636, "loss": "2.519", "nll_loss": "0.558", "ppl": "1.47", "wps": "3370", "ups": "8.89", "wpb": "379.2", "bsz": "32", "num_updates": "20200", "lr": "4.9039e-05", "gnorm": "3.67", "train_wall": "11", "wall": "4426"}
2022-08-18 05:37:01 | INFO | train_inner | {"epoch": 12, "update": 11.694, "loss": "2.567", "nll_loss": "0.614", "ppl": "1.53", "wps": "3401.9", "ups": "8.52", "wpb": "399.4", "bsz": "32", "num_updates": "20300", "lr": "4.9034e-05", "gnorm": "3.717", "train_wall": "12", "wall": "4437"}
2022-08-18 05:37:12 | INFO | train_inner | {"epoch": 12, "update": 11.751, "loss": "2.6", "nll_loss": "0.65", "ppl": "1.57", "wps": "3553.6", "ups": "8.45", "wpb": "420.6", "bsz": "32", "num_updates": "20400", "lr": "4.9029e-05", "gnorm": "3.744", "train_wall": "12", "wall": "4449"}
2022-08-18 05:37:25 | INFO | train_inner | {"epoch": 12, "update": 11.809, "loss": "2.593", "nll_loss": "0.639", "ppl": "1.56", "wps": "3320.7", "ups": "7.94", "wpb": "418.1", "bsz": "32", "num_updates": "20500", "lr": "4.9024e-05", "gnorm": "3.786", "train_wall": "12", "wall": "4462"}
2022-08-18 05:37:37 | INFO | train_inner | {"epoch": 12, "update": 11.866, "loss": "2.604", "nll_loss": "0.654", "ppl": "1.57", "wps": "3424.5", "ups": "8.12", "wpb": "421.6", "bsz": "32", "num_updates": "20600", "lr": "4.9019e-05", "gnorm": "3.766", "train_wall": "12", "wall": "4474"}
2022-08-18 05:37:50 | INFO | train_inner | {"epoch": 12, "update": 11.924, "loss": "2.601", "nll_loss": "0.654", "ppl": "1.57", "wps": "3327.7", "ups": "8.06", "wpb": "412.9", "bsz": "32", "num_updates": "20700", "lr": "4.9014e-05", "gnorm": "3.809", "train_wall": "12", "wall": "4487"}
2022-08-18 05:38:02 | INFO | train_inner | {"epoch": 12, "update": 11.982, "loss": "2.588", "nll_loss": "0.637", "ppl": "1.55", "wps": "3405.8", "ups": "8.29", "wpb": "411", "bsz": "32", "num_updates": "20800", "lr": "4.9009e-05", "gnorm": "3.812", "train_wall": "12", "wall": "4499"}
2022-08-18 05:38:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:41:24 | INFO | valid | {"epoch": 12, "valid_loss": "5.504", "valid_nll_loss": "3.868", "valid_ppl": "14.6", "valid_bleu": "26.05", "valid_wps": "1201.9", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "20832", "valid_best_bleu": "26.05"}
2022-08-18 05:41:24 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:41:29 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 12 @ 20832 updates, score 26.05) (writing took 5.1515345722436905 seconds)
2022-08-18 05:41:29 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2022-08-18 05:41:29 | INFO | train | {"epoch": 12, "train_loss": "2.56", "train_nll_loss": "0.603", "train_ppl": "1.52", "train_wps": "1715.8", "train_ups": "4.18", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "20832", "train_lr": "4.90074e-05", "train_gnorm": "3.604", "train_train_wall": "208", "train_wall": "4706"}
2022-08-18 05:41:29 | INFO | fairseq.trainer | begin training epoch 13
2022-08-18 05:41:38 | INFO | train_inner | {"epoch": 13, "update": 12.039, "loss": "2.503", "nll_loss": "0.542", "ppl": "1.46", "wps": "181.6", "ups": "0.46", "wpb": "392.5", "bsz": "32", "num_updates": "20900", "lr": "4.9004e-05", "gnorm": "3.261", "train_wall": "12", "wall": "4715"}
2022-08-18 05:41:50 | INFO | train_inner | {"epoch": 13, "update": 12.097, "loss": "2.466", "nll_loss": "0.498", "ppl": "1.41", "wps": "3317.2", "ups": "8.34", "wpb": "397.6", "bsz": "32", "num_updates": "21000", "lr": "4.8999e-05", "gnorm": "3.196", "train_wall": "12", "wall": "4727"}
2022-08-18 05:42:02 | INFO | train_inner | {"epoch": 13, "update": 12.154, "loss": "2.457", "nll_loss": "0.488", "ppl": "1.4", "wps": "3481.9", "ups": "8.57", "wpb": "406.2", "bsz": "32", "num_updates": "21100", "lr": "4.8994e-05", "gnorm": "3.229", "train_wall": "12", "wall": "4738"}
2022-08-18 05:42:15 | INFO | train_inner | {"epoch": 13, "update": 12.212, "loss": "2.473", "nll_loss": "0.505", "ppl": "1.42", "wps": "3241.4", "ups": "7.69", "wpb": "421.5", "bsz": "32", "num_updates": "21200", "lr": "4.8989e-05", "gnorm": "3.238", "train_wall": "13", "wall": "4751"}
2022-08-18 05:42:27 | INFO | train_inner | {"epoch": 13, "update": 12.27, "loss": "2.529", "nll_loss": "0.57", "ppl": "1.48", "wps": "3570.2", "ups": "8.21", "wpb": "435", "bsz": "32", "num_updates": "21300", "lr": "4.8984e-05", "gnorm": "3.321", "train_wall": "12", "wall": "4764"}
2022-08-18 05:42:38 | INFO | train_inner | {"epoch": 13, "update": 12.327, "loss": "2.481", "nll_loss": "0.517", "ppl": "1.43", "wps": "3624.4", "ups": "8.78", "wpb": "412.7", "bsz": "32", "num_updates": "21400", "lr": "4.8979e-05", "gnorm": "3.275", "train_wall": "11", "wall": "4775"}
2022-08-18 05:42:51 | INFO | train_inner | {"epoch": 13, "update": 12.385, "loss": "2.472", "nll_loss": "0.507", "ppl": "1.42", "wps": "3181.3", "ups": "7.95", "wpb": "400.1", "bsz": "32", "num_updates": "21500", "lr": "4.8974e-05", "gnorm": "3.346", "train_wall": "12", "wall": "4788"}
2022-08-18 05:43:03 | INFO | train_inner | {"epoch": 13, "update": 12.442, "loss": "2.47", "nll_loss": "0.508", "ppl": "1.42", "wps": "3366.8", "ups": "8.38", "wpb": "401.6", "bsz": "32", "num_updates": "21600", "lr": "4.8969e-05", "gnorm": "3.333", "train_wall": "12", "wall": "4800"}
2022-08-18 05:43:15 | INFO | train_inner | {"epoch": 13, "update": 12.5, "loss": "2.506", "nll_loss": "0.546", "ppl": "1.46", "wps": "3502", "ups": "8.43", "wpb": "415.3", "bsz": "32", "num_updates": "21700", "lr": "4.8964e-05", "gnorm": "3.451", "train_wall": "12", "wall": "4811"}
2022-08-18 05:43:26 | INFO | train_inner | {"epoch": 13, "update": 12.558, "loss": "2.519", "nll_loss": "0.563", "ppl": "1.48", "wps": "3387.6", "ups": "8.39", "wpb": "403.9", "bsz": "32", "num_updates": "21800", "lr": "4.8959e-05", "gnorm": "3.522", "train_wall": "12", "wall": "4823"}
2022-08-18 05:43:39 | INFO | train_inner | {"epoch": 13, "update": 12.615, "loss": "2.542", "nll_loss": "0.589", "ppl": "1.5", "wps": "3340.5", "ups": "8.01", "wpb": "417.1", "bsz": "32", "num_updates": "21900", "lr": "4.8954e-05", "gnorm": "3.504", "train_wall": "12", "wall": "4836"}
2022-08-18 05:43:51 | INFO | train_inner | {"epoch": 13, "update": 12.673, "loss": "2.531", "nll_loss": "0.574", "ppl": "1.49", "wps": "3594.6", "ups": "8.53", "wpb": "421.2", "bsz": "32", "num_updates": "22000", "lr": "4.89489e-05", "gnorm": "3.537", "train_wall": "12", "wall": "4847"}
2022-08-18 05:44:02 | INFO | train_inner | {"epoch": 13, "update": 12.73, "loss": "2.527", "nll_loss": "0.573", "ppl": "1.49", "wps": "3506.5", "ups": "8.72", "wpb": "401.9", "bsz": "32", "num_updates": "22100", "lr": "4.89439e-05", "gnorm": "3.605", "train_wall": "11", "wall": "4859"}
2022-08-18 05:44:15 | INFO | train_inner | {"epoch": 13, "update": 12.788, "loss": "2.528", "nll_loss": "0.573", "ppl": "1.49", "wps": "3413.5", "ups": "8.07", "wpb": "422.9", "bsz": "32", "num_updates": "22200", "lr": "4.89389e-05", "gnorm": "3.547", "train_wall": "12", "wall": "4871"}
2022-08-18 05:44:27 | INFO | train_inner | {"epoch": 13, "update": 12.846, "loss": "2.537", "nll_loss": "0.58", "ppl": "1.5", "wps": "3219.2", "ups": "7.78", "wpb": "413.5", "bsz": "32", "num_updates": "22300", "lr": "4.89339e-05", "gnorm": "3.601", "train_wall": "13", "wall": "4884"}
2022-08-18 05:44:40 | INFO | train_inner | {"epoch": 13, "update": 12.903, "loss": "2.568", "nll_loss": "0.62", "ppl": "1.54", "wps": "3285.2", "ups": "7.99", "wpb": "411.1", "bsz": "32", "num_updates": "22400", "lr": "4.89289e-05", "gnorm": "3.598", "train_wall": "12", "wall": "4897"}
2022-08-18 05:44:52 | INFO | train_inner | {"epoch": 13, "update": 12.961, "loss": "2.566", "nll_loss": "0.617", "ppl": "1.53", "wps": "3350.1", "ups": "8.24", "wpb": "406.4", "bsz": "32", "num_updates": "22500", "lr": "4.89239e-05", "gnorm": "3.698", "train_wall": "12", "wall": "4909"}
2022-08-18 05:45:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:48:07 | INFO | valid | {"epoch": 13, "valid_loss": "5.546", "valid_nll_loss": "3.927", "valid_ppl": "15.21", "valid_bleu": "25.89", "valid_wps": "1279.1", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "22568", "valid_best_bleu": "26.05"}
2022-08-18 05:48:07 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:48:11 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_last.pt (epoch 13 @ 22568 updates, score 25.89) (writing took 3.7970692813396454 seconds)
2022-08-18 05:48:11 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2022-08-18 05:48:11 | INFO | train | {"epoch": 13, "train_loss": "2.508", "train_nll_loss": "0.549", "train_ppl": "1.46", "train_wps": "1773", "train_ups": "4.32", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "22568", "train_lr": "4.89205e-05", "train_gnorm": "3.428", "train_train_wall": "208", "train_wall": "5108"}
2022-08-18 05:48:11 | INFO | fairseq.trainer | begin training epoch 14
2022-08-18 05:48:16 | INFO | train_inner | {"epoch": 14, "update": 13.018, "loss": "2.514", "nll_loss": "0.553", "ppl": "1.47", "wps": "204.5", "ups": "0.49", "wpb": "416.1", "bsz": "31.9", "num_updates": "22600", "lr": "4.89189e-05", "gnorm": "3.465", "train_wall": "12", "wall": "5112"}
2022-08-18 05:48:29 | INFO | train_inner | {"epoch": 14, "update": 13.076, "loss": "2.428", "nll_loss": "0.457", "ppl": "1.37", "wps": "3189.3", "ups": "7.66", "wpb": "416.4", "bsz": "32", "num_updates": "22700", "lr": "4.89139e-05", "gnorm": "3.064", "train_wall": "13", "wall": "5125"}
2022-08-18 05:48:41 | INFO | train_inner | {"epoch": 14, "update": 13.134, "loss": "2.426", "nll_loss": "0.459", "ppl": "1.37", "wps": "3312.8", "ups": "7.98", "wpb": "415.1", "bsz": "32", "num_updates": "22800", "lr": "4.89089e-05", "gnorm": "3.022", "train_wall": "12", "wall": "5138"}
2022-08-18 05:48:53 | INFO | train_inner | {"epoch": 14, "update": 13.191, "loss": "2.419", "nll_loss": "0.452", "ppl": "1.37", "wps": "3419.2", "ups": "8.62", "wpb": "396.5", "bsz": "32", "num_updates": "22900", "lr": "4.89039e-05", "gnorm": "3.035", "train_wall": "11", "wall": "5149"}
2022-08-18 05:49:04 | INFO | train_inner | {"epoch": 14, "update": 13.249, "loss": "2.442", "nll_loss": "0.476", "ppl": "1.39", "wps": "3523.4", "ups": "8.83", "wpb": "399.2", "bsz": "32", "num_updates": "23000", "lr": "4.88989e-05", "gnorm": "3.165", "train_wall": "11", "wall": "5161"}
2022-08-18 05:49:15 | INFO | train_inner | {"epoch": 14, "update": 13.306, "loss": "2.461", "nll_loss": "0.502", "ppl": "1.42", "wps": "3531.4", "ups": "8.73", "wpb": "404.4", "bsz": "32", "num_updates": "23100", "lr": "4.88939e-05", "gnorm": "3.182", "train_wall": "11", "wall": "5172"}
2022-08-18 05:49:27 | INFO | train_inner | {"epoch": 14, "update": 13.364, "loss": "2.445", "nll_loss": "0.485", "ppl": "1.4", "wps": "3313.3", "ups": "8.49", "wpb": "390.5", "bsz": "32", "num_updates": "23200", "lr": "4.88889e-05", "gnorm": "3.187", "train_wall": "12", "wall": "5184"}
2022-08-18 05:49:39 | INFO | train_inner | {"epoch": 14, "update": 13.422, "loss": "2.445", "nll_loss": "0.483", "ppl": "1.4", "wps": "3373.7", "ups": "8.43", "wpb": "400.3", "bsz": "32", "num_updates": "23300", "lr": "4.88839e-05", "gnorm": "3.23", "train_wall": "12", "wall": "5196"}
2022-08-18 05:49:51 | INFO | train_inner | {"epoch": 14, "update": 13.479, "loss": "2.474", "nll_loss": "0.516", "ppl": "1.43", "wps": "3350.7", "ups": "8.18", "wpb": "409.7", "bsz": "32", "num_updates": "23400", "lr": "4.88789e-05", "gnorm": "3.347", "train_wall": "12", "wall": "5208"}
2022-08-18 05:50:04 | INFO | train_inner | {"epoch": 14, "update": 13.537, "loss": "2.475", "nll_loss": "0.516", "ppl": "1.43", "wps": "3349.6", "ups": "8.12", "wpb": "412.7", "bsz": "32", "num_updates": "23500", "lr": "4.88739e-05", "gnorm": "3.335", "train_wall": "12", "wall": "5220"}
2022-08-18 05:50:16 | INFO | train_inner | {"epoch": 14, "update": 13.594, "loss": "2.499", "nll_loss": "0.543", "ppl": "1.46", "wps": "3363.4", "ups": "7.81", "wpb": "430.7", "bsz": "31.9", "num_updates": "23600", "lr": "4.88689e-05", "gnorm": "3.354", "train_wall": "13", "wall": "5233"}
2022-08-18 05:50:28 | INFO | train_inner | {"epoch": 14, "update": 13.652, "loss": "2.485", "nll_loss": "0.529", "ppl": "1.44", "wps": "3562.2", "ups": "8.62", "wpb": "413.3", "bsz": "32", "num_updates": "23700", "lr": "4.88639e-05", "gnorm": "3.413", "train_wall": "11", "wall": "5245"}
2022-08-18 05:50:40 | INFO | train_inner | {"epoch": 14, "update": 13.71, "loss": "2.491", "nll_loss": "0.535", "ppl": "1.45", "wps": "3398.7", "ups": "8.13", "wpb": "417.8", "bsz": "32", "num_updates": "23800", "lr": "4.88589e-05", "gnorm": "3.342", "train_wall": "12", "wall": "5257"}
2022-08-18 05:50:53 | INFO | train_inner | {"epoch": 14, "update": 13.767, "loss": "2.489", "nll_loss": "0.531", "ppl": "1.44", "wps": "3200.5", "ups": "7.73", "wpb": "414", "bsz": "32", "num_updates": "23900", "lr": "4.88539e-05", "gnorm": "3.41", "train_wall": "13", "wall": "5270"}
2022-08-18 05:51:05 | INFO | train_inner | {"epoch": 14, "update": 13.825, "loss": "2.453", "nll_loss": "0.495", "ppl": "1.41", "wps": "3308.6", "ups": "8.61", "wpb": "384.1", "bsz": "32", "num_updates": "24000", "lr": "4.88488e-05", "gnorm": "3.398", "train_wall": "11", "wall": "5282"}
2022-08-18 05:51:17 | INFO | train_inner | {"epoch": 14, "update": 13.882, "loss": "2.484", "nll_loss": "0.527", "ppl": "1.44", "wps": "3316.4", "ups": "8.19", "wpb": "404.9", "bsz": "32", "num_updates": "24100", "lr": "4.88438e-05", "gnorm": "3.447", "train_wall": "12", "wall": "5294"}
2022-08-18 05:51:29 | INFO | train_inner | {"epoch": 14, "update": 13.94, "loss": "2.527", "nll_loss": "0.578", "ppl": "1.49", "wps": "3367.5", "ups": "8.1", "wpb": "415.6", "bsz": "32", "num_updates": "24200", "lr": "4.88388e-05", "gnorm": "3.527", "train_wall": "12", "wall": "5306"}
2022-08-18 05:51:41 | INFO | train_inner | {"epoch": 14, "update": 13.998, "loss": "2.543", "nll_loss": "0.594", "ppl": "1.51", "wps": "3674.1", "ups": "8.36", "wpb": "439.6", "bsz": "32", "num_updates": "24300", "lr": "4.88338e-05", "gnorm": "3.522", "train_wall": "12", "wall": "5318"}
2022-08-18 05:51:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 05:54:49 | INFO | valid | {"epoch": 14, "valid_loss": "5.564", "valid_nll_loss": "3.968", "valid_ppl": "15.65", "valid_bleu": "26.48", "valid_wps": "1275.1", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "24304", "valid_best_bleu": "26.48"}
2022-08-18 05:54:49 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 05:54:54 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 14 @ 24304 updates, score 26.48) (writing took 5.090232901275158 seconds)
2022-08-18 05:54:54 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-08-18 05:54:54 | INFO | train | {"epoch": 14, "train_loss": "2.471", "train_nll_loss": "0.511", "train_ppl": "1.43", "train_wps": "1765.3", "train_ups": "4.3", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "24304", "train_lr": "4.88336e-05", "train_gnorm": "3.288", "train_train_wall": "208", "train_wall": "5511"}
2022-08-18 05:54:54 | INFO | fairseq.trainer | begin training epoch 15
2022-08-18 05:55:06 | INFO | train_inner | {"epoch": 15, "update": 14.055, "loss": "2.399", "nll_loss": "0.43", "ppl": "1.35", "wps": "195.5", "ups": "0.49", "wpb": "399.6", "bsz": "32", "num_updates": "24400", "lr": "4.88288e-05", "gnorm": "2.938", "train_wall": "11", "wall": "5523"}
2022-08-18 05:55:18 | INFO | train_inner | {"epoch": 15, "update": 14.113, "loss": "2.418", "nll_loss": "0.452", "ppl": "1.37", "wps": "3395.1", "ups": "8.03", "wpb": "422.7", "bsz": "32", "num_updates": "24500", "lr": "4.88238e-05", "gnorm": "2.935", "train_wall": "12", "wall": "5535"}
2022-08-18 05:55:30 | INFO | train_inner | {"epoch": 15, "update": 14.171, "loss": "2.394", "nll_loss": "0.429", "ppl": "1.35", "wps": "3357.1", "ups": "8.43", "wpb": "398", "bsz": "32", "num_updates": "24600", "lr": "4.88188e-05", "gnorm": "2.89", "train_wall": "12", "wall": "5547"}
2022-08-18 05:55:42 | INFO | train_inner | {"epoch": 15, "update": 14.228, "loss": "2.389", "nll_loss": "0.423", "ppl": "1.34", "wps": "3263.4", "ups": "8.44", "wpb": "386.9", "bsz": "32", "num_updates": "24700", "lr": "4.88138e-05", "gnorm": "3.008", "train_wall": "12", "wall": "5559"}
2022-08-18 05:55:54 | INFO | train_inner | {"epoch": 15, "update": 14.286, "loss": "2.47", "nll_loss": "0.513", "ppl": "1.43", "wps": "3673.8", "ups": "8.44", "wpb": "435.3", "bsz": "32", "num_updates": "24800", "lr": "4.88088e-05", "gnorm": "3.139", "train_wall": "12", "wall": "5571"}
2022-08-18 05:56:06 | INFO | train_inner | {"epoch": 15, "update": 14.343, "loss": "2.421", "nll_loss": "0.459", "ppl": "1.37", "wps": "3429.8", "ups": "8.47", "wpb": "405.1", "bsz": "32", "num_updates": "24900", "lr": "4.88038e-05", "gnorm": "3.125", "train_wall": "12", "wall": "5582"}
2022-08-18 05:56:18 | INFO | train_inner | {"epoch": 15, "update": 14.401, "loss": "2.432", "nll_loss": "0.473", "ppl": "1.39", "wps": "3293.9", "ups": "8.4", "wpb": "392.1", "bsz": "32", "num_updates": "25000", "lr": "4.87988e-05", "gnorm": "3.14", "train_wall": "12", "wall": "5594"}
2022-08-18 05:56:30 | INFO | train_inner | {"epoch": 15, "update": 14.459, "loss": "2.419", "nll_loss": "0.457", "ppl": "1.37", "wps": "3368.1", "ups": "8.25", "wpb": "408.2", "bsz": "31.9", "num_updates": "25100", "lr": "4.87938e-05", "gnorm": "3.075", "train_wall": "12", "wall": "5606"}
2022-08-18 05:56:42 | INFO | train_inner | {"epoch": 15, "update": 14.516, "loss": "2.463", "nll_loss": "0.509", "ppl": "1.42", "wps": "3419.1", "ups": "8.12", "wpb": "420.8", "bsz": "32", "num_updates": "25200", "lr": "4.87888e-05", "gnorm": "3.119", "train_wall": "12", "wall": "5619"}
2022-08-18 05:56:54 | INFO | train_inner | {"epoch": 15, "update": 14.574, "loss": "2.415", "nll_loss": "0.455", "ppl": "1.37", "wps": "3215.7", "ups": "8.25", "wpb": "389.6", "bsz": "32", "num_updates": "25300", "lr": "4.87838e-05", "gnorm": "3.162", "train_wall": "12", "wall": "5631"}
2022-08-18 05:57:07 | INFO | train_inner | {"epoch": 15, "update": 14.631, "loss": "2.435", "nll_loss": "0.476", "ppl": "1.39", "wps": "3252.4", "ups": "7.98", "wpb": "407.6", "bsz": "32", "num_updates": "25400", "lr": "4.87788e-05", "gnorm": "3.196", "train_wall": "12", "wall": "5643"}
2022-08-18 05:57:19 | INFO | train_inner | {"epoch": 15, "update": 14.689, "loss": "2.475", "nll_loss": "0.52", "ppl": "1.43", "wps": "3580.7", "ups": "8.27", "wpb": "432.8", "bsz": "32", "num_updates": "25500", "lr": "4.87738e-05", "gnorm": "3.314", "train_wall": "12", "wall": "5655"}
2022-08-18 05:57:31 | INFO | train_inner | {"epoch": 15, "update": 14.747, "loss": "2.457", "nll_loss": "0.502", "ppl": "1.42", "wps": "3504.8", "ups": "8.35", "wpb": "419.7", "bsz": "32", "num_updates": "25600", "lr": "4.87688e-05", "gnorm": "3.253", "train_wall": "12", "wall": "5667"}
2022-08-18 05:57:44 | INFO | train_inner | {"epoch": 15, "update": 14.804, "loss": "2.463", "nll_loss": "0.506", "ppl": "1.42", "wps": "3202", "ups": "7.56", "wpb": "423.5", "bsz": "32", "num_updates": "25700", "lr": "4.87638e-05", "gnorm": "3.225", "train_wall": "13", "wall": "5681"}
2022-08-18 05:57:56 | INFO | train_inner | {"epoch": 15, "update": 14.862, "loss": "2.467", "nll_loss": "0.512", "ppl": "1.43", "wps": "3389.6", "ups": "8.04", "wpb": "421.7", "bsz": "32", "num_updates": "25800", "lr": "4.87588e-05", "gnorm": "3.298", "train_wall": "12", "wall": "5693"}
2022-08-18 05:58:09 | INFO | train_inner | {"epoch": 15, "update": 14.919, "loss": "2.474", "nll_loss": "0.523", "ppl": "1.44", "wps": "3266.2", "ups": "8", "wpb": "408.2", "bsz": "32", "num_updates": "25900", "lr": "4.87538e-05", "gnorm": "3.346", "train_wall": "12", "wall": "5706"}
2022-08-18 05:58:21 | INFO | train_inner | {"epoch": 15, "update": 14.977, "loss": "2.487", "nll_loss": "0.537", "ppl": "1.45", "wps": "3457.4", "ups": "8.41", "wpb": "411.2", "bsz": "32", "num_updates": "26000", "lr": "4.87487e-05", "gnorm": "3.41", "train_wall": "12", "wall": "5718"}
2022-08-18 05:58:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-08-18 06:01:32 | INFO | valid | {"epoch": 15, "valid_loss": "5.578", "valid_nll_loss": "3.982", "valid_ppl": "15.8", "valid_bleu": "26.53", "valid_wps": "1281", "valid_wpb": "411.1", "valid_bsz": "32", "valid_num_updates": "26040", "valid_best_bleu": "26.53"}
2022-08-18 06:01:32 | INFO | fairseq_cli.train | begin save checkpoint
2022-08-18 06:01:37 | INFO | fairseq.checkpoint_utils | saved checkpoint /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt (epoch 15 @ 26040 updates, score 26.53) (writing took 5.1271126717329025 seconds)
2022-08-18 06:01:37 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2022-08-18 06:01:37 | INFO | train | {"epoch": 15, "train_loss": "2.441", "train_nll_loss": "0.482", "train_ppl": "1.4", "train_wps": "1767.7", "train_ups": "4.31", "train_wpb": "410.2", "train_bsz": "32", "train_num_updates": "26040", "train_lr": "4.87467e-05", "train_gnorm": "3.153", "train_train_wall": "208", "train_wall": "5914"}
2022-08-18 06:01:37 | INFO | fairseq_cli.train | done training in 5911.4 seconds
@ Completed
@ Stage 3
Create Datastore
2022-08-18 06:01:39 | INFO | fairseq_cli.validate | loading model(s) from /home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt
2022-08-18 06:01:40 | INFO | fairseq.tasks.translation | [python] dictionary: 50001 types
2022-08-18 06:01:40 | INFO | fairseq.tasks.translation | [en_XX] dictionary: 50001 types
2022-08-18 06:01:47 | INFO | fairseq_cli.validate | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='mbart_base', attention_dropout=0.0, batch_size=32, batch_size_valid=32, best_checkpoint_metric='bleu', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin', data_buffer_size=10, dataset_impl='mmap', ddp_backend='no_c10d', decoder_attention_heads=12, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=768, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, dstore_filename=None, dstore_fp16=True, dstore_mmap='/home/cluster/jgu/scratch/ssr/cli/out/mix/python/half_datastore', dstore_size=601026, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=True, eval_bleu_args='{"beam": 6}', eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe='sentencepiece', eval_tokenized_bleu=True, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, k=5, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, knn_lambda=0.5, knn_sim_metric=None, knn_temperature=10, label_smoothing=0.1, langs='java,python,en_XX', layernorm_embedding=True, left_pad_source=False, left_pad_target=False, load_alignments=False, localsgd_frequency=3, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=15, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=None, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, move_dstore_to_mem=False, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, only_train_final_output=False, optimizer='adam', optimizer_overrides='{}', partially_finetune=False, path='/home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX/checkpoint_best.pt', patience=5, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, prepend_bos=False, probe=32, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='/home/cluster/jgu/scratch/ssr/cli/model/plbart_base.pt', save_dir='/home/cluster/jgu/scratch/ssr/cli/out/mix/half_base_python_en_XX', save_interval=1, save_interval_updates=0, scoring='bleu', seed=42, sentence_avg=False, sentencepiece_model='/home/cluster/jgu/scratch/ssr/cli/sentencepiece/sentencepiece.bpe.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='python', stop_time_hours=0, target_lang='en_XX', task='translation_from_pretrained_bart', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_gpu_to_search=False, use_knn_datastore=False, use_old_adam=False, user_dir='/home/cluster/jgu/scratch/ssr/cli', valid_subset='train', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=1000, weight_decay=0.0, zero_sharding='none')
Saving fp16
2022-08-18 06:01:47 | INFO | fairseq.data.data_utils | loaded 55538 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/train.python-en_XX.python
2022-08-18 06:01:47 | INFO | fairseq.data.data_utils | loaded 55538 examples from: /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin/train.python-en_XX.en_XX
2022-08-18 06:01:47 | INFO | fairseq.tasks.translation | /home/cluster/jgu/scratch/ssr/cli/out/mix/python/data-bin train python-en_XX 55538 examples
/home/cluster/jgu/scratch/ssr/cli/ds_build.py:69: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  dstore_vals = np.memmap(args.dstore_mmap + '/vals.npy', dtype=np.int, mode='w+',
/home/cluster/jgu/scratch/ssr/cli/ds_build.py:157: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  dstore_vals[dstore_idx:reduce_size + dstore_idx] = target.unsqueeze(-1).cpu().numpy().astype(np.int)
1376
2939
3541
5902
6393
9091
10412
10999
13774
15437
18306
20298
20887
23807
26148
26605
29326
32183
33513
36086
39168
40421
42623
45760
48170
48884
51006
53977
56292
56947
58920
61581
64697
66030
67665
69959
72934
74635
76332
78602
81525
83264
83953
85604
87772
90564
92601
93233
94771
96770
99183
101997
103220
104620
106474
108760
111402
112237
113571
115292
117357
119919
121736
122862
124420
126337
128678
130435
131235
132627
134368
136462
139196
140197
141476
143030
144872
147155
148759
149875
151335
153113
155326
156975
157528
158601
159937
161511
163379
165820
167045
168226
169672
171407
173534
175239
176218
177459
178909
180591
182806
183807
184855
186173
187699
189524
191509
192202
193213
194451
195908
197652
199610
200355
201436
202771
204347
206289
207701
208248
209147
210260
211577
213145
215136
216095
217002
218118
219423
220972
222910
223772
224536
225516
226662
227992
229536
231589
232589
233484
234558
235796
237239
238960
240794
241481
242420
243551
244866
246445
248085
248759
249571
250572
251719
253071
254768
256034
256784
257702
258791
260044
261535
263236
264030
264855
265839
266974
268294
269980
271789
272411
273228
274183
275285
276576
278196
279352
280018
280849
281800
282898
284200
285952
286652
287429
288333
289358
290525
291868
293710
294528
295266
296169
297188
298359
299738
301385
301922
302619
303457
304437
305551
306836
308253
308803
309473
310283
311221
312296
313598
315358
315911
316631
317485
318480
319630
321048
322466
323069
323842
324747
325796
327004
328595
329452
330161
331000
331983
333128
334529
335696
336253
336929
337707
338602
339657
340965
342366
342920
343596
344375
345269
346300
347579
348677
349236
349956
350804
351808
353041
354305
354812
355478
356260
357171
358235
359806
360451
361103
361882
362802
363887
365319
366272
366768
367365
368046
368842
369753
370832
371942
372445
373058
373753
374557
375512
376759
377730
378248
378863
379578
380377
381334
382683
383196
383784
384460
385249
386153
387309
388237
388780
389443
390191
391076
392112
393456
393940
394558
395282
396123
397157
398551
399020
399623
400343
401167
402161
403639
404168
404770
405495
406365
407462
408463
408899
409441
410051
410733
411524
412484
413828
414231
414740
415318
415989
416792
417812
418661
419135
419711
420373
421120
421975
423079
423970
424450
425037
425747
426584
427586
428611
429060
429617
430256
430977
431810
432898
433565
434043
434609
435247
435979
436849
438125
438519
439014
439598
440271
441043
441947
443147
443578
444119
444757
445493
446386
447705
448100
448608
449189
449853
450640
451592
452719
453079
453517
454018
454568
455199
455910
456776
457452
457850
458329
458884
459520
460262
461276
461950
462347
462836
463391
464035
464802
465911
466240
466672
467205
467821
468549
469463
470080
470464
470925
471464
472076
472803
473736
474262
474671
475153
475718
476370
477133
478262
478698
479136
479653
480268
481012
482077
482551
483004
483536
484143
484851
485838
486439
486844
487321
487876
488523
489291
490336
490671
491121
491655
492291
493031
494143
494483
494934
495476
496106
496864
497953
498309
498780
499342
500004
500828
501628
501936
502313
502745
503240
503808
504473
505287
505578
505941
506355
506831
507381
508028
508954
509339
509684
510092
510570
511125
511823
512696
513002
513385
513844
514384
515005
515790
516522
516834
517226
517688
518230
518885
519629
519917
520286
520734
521253
521863
522725
523065
523443
523891
524410
525055
525928
526202
526547
526961
527457
528018
528705
529321
529648
530053
530528
531094
531899
532395
532742
533149
533617
534162
534806
535560
535878
536278
536742
537267
537937
538902
539193
539586
540045
540575
541243
541886
542226
542637
543121
543664
544322
544898
545228
545637
546114
546682
547376
548072
548407
548834
549350
549962
550728
551311
551660
552084
552599
553233
554207
554561
554930
555390
555949
556665
557146
557435
557766
558142
558583
559115
559790
560039
560371
560752
561195
561706
562354
562864
563138
563480
563877
564331
564884
565330
565594
565912
566289
566745
567284
567970
568207
568508
568848
569234
569678
570213
570971
571185
571460
571809
572210
572689
573376
573770
574054
574404
574816
575311
576001
576338
576614
576946
577341
577823
578467
578973
579235
579558
579943
580384
580948
581728
581950
582241
582606
583025
583523
584231
584460
584792
585181
585626
586198
586803
587058
587381
587758
588206
588797
589318
589598
589960
590386
590916
591706
591955
592271
592648
593085
593616
594144
594425
594781
595203
595739
596457
596682
596977
597336
597762
598312
598828
599092
599408
599776
600197
600707
601026
much more than dstore size break
Build Faiss Index
/home/cluster/jgu/scratch/ssr/cli/ds_train.py:28: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  vals = np.memmap(args.dstore_mmap + '/vals.npy', dtype=np.int, mode='r', shape=(args.dstore_size, 1))
Namespace(code_size=64, dimension=768, dstore_fp16=True, dstore_mmap='/home/cluster/jgu/scratch/ssr/cli/out/mix/python/half_datastore', dstore_size=601026, faiss_index='/home/cluster/jgu/scratch/ssr/cli/out/mix/python/half_datastore/knn_index', ncentroids=4096, probe=32, seed=1, starting_point=0)
done.
Start put index to gpu
Training Index
[372585  13403 243731 423153 392567 512461 516163 453239  41018 558783]
[[-1.694   -0.2172   2.42    ...  0.475    1.936   -1.606  ]
 [-3.78     0.9883   1.53    ... -2.219    0.1588   3.518  ]
 [ 1.808   -0.087    0.3206  ... -0.403    0.09314  0.2153 ]
 ...
 [ 1.231   -0.1976  -0.4785  ... -1.091    0.567    1.936  ]
 [-0.6987   2.527    4.754   ... -0.9277   0.01862 -1.598  ]
 [-3.336   -1.568    1.28    ... -0.3335  -0.833    0.6553 ]]
Training took 18.272740364074707 s
Writing index after training
Writing index took 0.038022518157958984 s
Adding Keys
Added 1000000 tokens so far
Writing Index 1000000
Adding total 601026 keys
Adding took 3.902970314025879 s
Writing Index
Writing index took 0.13292694091796875 s
@ Completed
@ Stage 4
/net/cephfs/scratch/jgu/ssr/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  beams_buf = indices_buf // vocab_size
/net/cephfs/scratch/jgu/ssr/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  unfin_idx = idx // beam_size
WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.
c_bleu = 26.31 | s_bleu = 34.92 | meteor = 22.72 | rouge = 45.13
@ Completed
